{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to keep only 100 instances per class in the training set \n",
    "# and let's keep only 30 instances per class in the validation set\n",
    "# tesing set is already loaded above\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3.1 Only Softmax trainable for predict 5 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"logits/BiasAdd:0\", shape=(?, 5), dtype=float32)\n",
      "[<tf.Variable 'logits/kernel:0' shape=(128, 5) dtype=float32_ref>, <tf.Variable 'logits/bias:0' shape=(5,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "# For AdamOptimizer\n",
    "learning_rate = 0.001\n",
    "\n",
    "# import model from HW2\n",
    "restore_saver = tf.train.import_meta_graph(\"./hw2_model/Team20_HW2.ckpt.meta\")\n",
    "\n",
    "# Step1: Get tensor from HW2 model\n",
    "x = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"Y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")\n",
    "training_mode = tf.get_default_graph().get_tensor_by_name(\"is_training:0\")\n",
    "\n",
    "# Step2: Get the outputs of our softmax layer, see tensorboard to know the output of logits tensor is logits/BiasAdd.\n",
    "logits = tf.get_default_graph().get_tensor_by_name(\"logits/BiasAdd:0\")\n",
    "\n",
    "# Step3: Only let softmax layer trainable\n",
    "output_layer = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='logits')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name='opt1')\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer)\n",
    "\n",
    "print(logits)\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To calculate prediction result and accuracy\n",
    "prediction = tf.argmax(logits, 1, output_type=tf.int32)\n",
    "correct_prediction = tf.equal(prediction, tf.cast(y, tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For initialize\n",
    "init_g = tf.global_variables_initializer()\n",
    "\n",
    "# Saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./hw2_model/Team20_HW2.ckpt\n",
      "Epoch 0: Validation loss: 4.056200981140137 Best loss: 4.056200981140137 Accuracy: 0.2666666507720947 \n",
      "Epoch 1: Validation loss: 3.7506089210510254 Best loss: 3.7506089210510254 Accuracy: 0.273333340883255 \n",
      "Epoch 2: Validation loss: 3.4611799716949463 Best loss: 3.4611799716949463 Accuracy: 0.29333335161209106 \n",
      "Epoch 3: Validation loss: 3.190791606903076 Best loss: 3.190791606903076 Accuracy: 0.30666667222976685 \n",
      "Epoch 4: Validation loss: 2.940844774246216 Best loss: 2.940844774246216 Accuracy: 0.3333333134651184 \n",
      "Epoch 5: Validation loss: 2.71216082572937 Best loss: 2.71216082572937 Accuracy: 0.3399999737739563 \n",
      "Epoch 6: Validation loss: 2.5051674842834473 Best loss: 2.5051674842834473 Accuracy: 0.36666664481163025 \n",
      "Epoch 7: Validation loss: 2.319786787033081 Best loss: 2.319786787033081 Accuracy: 0.42666664719581604 \n",
      "Epoch 8: Validation loss: 2.1552441120147705 Best loss: 2.1552441120147705 Accuracy: 0.4399999976158142 \n",
      "Epoch 9: Validation loss: 2.0100226402282715 Best loss: 2.0100226402282715 Accuracy: 0.4599999785423279 \n",
      "Epoch 10: Validation loss: 1.882073998451233 Best loss: 1.882073998451233 Accuracy: 0.48000001907348633 \n",
      "Epoch 11: Validation loss: 1.7691736221313477 Best loss: 1.7691736221313477 Accuracy: 0.5 \n",
      "Epoch 12: Validation loss: 1.669235348701477 Best loss: 1.669235348701477 Accuracy: 0.5133333206176758 \n",
      "Epoch 13: Validation loss: 1.5804730653762817 Best loss: 1.5804730653762817 Accuracy: 0.5133333206176758 \n",
      "Epoch 14: Validation loss: 1.501415491104126 Best loss: 1.501415491104126 Accuracy: 0.5266667008399963 \n",
      "Epoch 15: Validation loss: 1.4308536052703857 Best loss: 1.4308536052703857 Accuracy: 0.5266666412353516 \n",
      "Epoch 16: Validation loss: 1.3677737712860107 Best loss: 1.3677737712860107 Accuracy: 0.5666666626930237 \n",
      "Epoch 17: Validation loss: 1.3113075494766235 Best loss: 1.3113075494766235 Accuracy: 0.5866666436195374 \n",
      "Epoch 18: Validation loss: 1.2606942653656006 Best loss: 1.2606942653656006 Accuracy: 0.6200000047683716 \n",
      "Epoch 19: Validation loss: 1.2152531147003174 Best loss: 1.2152531147003174 Accuracy: 0.6266666650772095 \n",
      "Epoch 20: Validation loss: 1.1743674278259277 Best loss: 1.1743674278259277 Accuracy: 0.6266666650772095 \n",
      "Epoch 21: Validation loss: 1.1374757289886475 Best loss: 1.1374757289886475 Accuracy: 0.6399999856948853 \n",
      "Epoch 22: Validation loss: 1.104069709777832 Best loss: 1.104069709777832 Accuracy: 0.6466666460037231 \n",
      "Epoch 23: Validation loss: 1.0736980438232422 Best loss: 1.0736980438232422 Accuracy: 0.6399999856948853 \n",
      "Epoch 24: Validation loss: 1.0459693670272827 Best loss: 1.0459693670272827 Accuracy: 0.6466666460037231 \n",
      "Epoch 25: Validation loss: 1.0205498933792114 Best loss: 1.0205498933792114 Accuracy: 0.653333306312561 \n",
      "Epoch 26: Validation loss: 0.9971588850021362 Best loss: 0.9971588850021362 Accuracy: 0.6599999666213989 \n",
      "Epoch 27: Validation loss: 0.975560188293457 Best loss: 0.975560188293457 Accuracy: 0.6866666674613953 \n",
      "Epoch 28: Validation loss: 0.9555548429489136 Best loss: 0.9555548429489136 Accuracy: 0.6933333277702332 \n",
      "Epoch 29: Validation loss: 0.9369737505912781 Best loss: 0.9369737505912781 Accuracy: 0.6933333277702332 \n",
      "Epoch 30: Validation loss: 0.9196711778640747 Best loss: 0.9196711778640747 Accuracy: 0.6866666078567505 \n",
      "Epoch 31: Validation loss: 0.9035205841064453 Best loss: 0.9035205841064453 Accuracy: 0.6800000071525574 \n",
      "Epoch 32: Validation loss: 0.888410747051239 Best loss: 0.888410747051239 Accuracy: 0.6933332681655884 \n",
      "Epoch 33: Validation loss: 0.874243974685669 Best loss: 0.874243974685669 Accuracy: 0.699999988079071 \n",
      "Epoch 34: Validation loss: 0.8609329462051392 Best loss: 0.8609329462051392 Accuracy: 0.699999988079071 \n",
      "Epoch 35: Validation loss: 0.848399817943573 Best loss: 0.848399817943573 Accuracy: 0.7066666483879089 \n",
      "Epoch 36: Validation loss: 0.836575448513031 Best loss: 0.836575448513031 Accuracy: 0.7066667079925537 \n",
      "Epoch 37: Validation loss: 0.8253979682922363 Best loss: 0.8253979682922363 Accuracy: 0.7200000286102295 \n",
      "Epoch 38: Validation loss: 0.8148122429847717 Best loss: 0.8148122429847717 Accuracy: 0.7266666889190674 \n",
      "Epoch 39: Validation loss: 0.8047689199447632 Best loss: 0.8047689199447632 Accuracy: 0.7266666889190674 \n",
      "Epoch 40: Validation loss: 0.795224666595459 Best loss: 0.795224666595459 Accuracy: 0.7333333492279053 \n",
      "Epoch 41: Validation loss: 0.7861402034759521 Best loss: 0.7861402034759521 Accuracy: 0.7333333492279053 \n",
      "Epoch 42: Validation loss: 0.7774810791015625 Best loss: 0.7774810791015625 Accuracy: 0.746666669845581 \n",
      "Epoch 43: Validation loss: 0.7692161798477173 Best loss: 0.7692161798477173 Accuracy: 0.746666669845581 \n",
      "Epoch 44: Validation loss: 0.7613183259963989 Best loss: 0.7613183259963989 Accuracy: 0.746666669845581 \n",
      "Epoch 45: Validation loss: 0.753762423992157 Best loss: 0.753762423992157 Accuracy: 0.753333330154419 \n",
      "Epoch 46: Validation loss: 0.7465263605117798 Best loss: 0.7465263605117798 Accuracy: 0.753333330154419 \n",
      "Epoch 47: Validation loss: 0.7395901083946228 Best loss: 0.7395901083946228 Accuracy: 0.7599999904632568 \n",
      "Epoch 48: Validation loss: 0.7329350113868713 Best loss: 0.7329350113868713 Accuracy: 0.7599999904632568 \n",
      "Epoch 49: Validation loss: 0.7265447378158569 Best loss: 0.7265447378158569 Accuracy: 0.7666666507720947 \n",
      "Epoch 50: Validation loss: 0.7204034328460693 Best loss: 0.7204034328460693 Accuracy: 0.7666666507720947 \n",
      "Epoch 51: Validation loss: 0.7144970893859863 Best loss: 0.7144970893859863 Accuracy: 0.7666666507720947 \n",
      "Epoch 52: Validation loss: 0.7088125348091125 Best loss: 0.7088125348091125 Accuracy: 0.7666666507720947 \n",
      "Epoch 53: Validation loss: 0.7033374309539795 Best loss: 0.7033374309539795 Accuracy: 0.7666666507720947 \n",
      "Epoch 54: Validation loss: 0.698060154914856 Best loss: 0.698060154914856 Accuracy: 0.7666666507720947 \n",
      "Epoch 55: Validation loss: 0.6929702758789062 Best loss: 0.6929702758789062 Accuracy: 0.7666666507720947 \n",
      "Epoch 56: Validation loss: 0.6880577802658081 Best loss: 0.6880577802658081 Accuracy: 0.7666666507720947 \n",
      "Epoch 57: Validation loss: 0.6833131909370422 Best loss: 0.6833131909370422 Accuracy: 0.7733333110809326 \n",
      "Epoch 58: Validation loss: 0.678727924823761 Best loss: 0.678727924823761 Accuracy: 0.7733333110809326 \n",
      "Epoch 59: Validation loss: 0.6742936372756958 Best loss: 0.6742936372756958 Accuracy: 0.7733333110809326 \n",
      "Epoch 60: Validation loss: 0.6700029373168945 Best loss: 0.6700029373168945 Accuracy: 0.7733333110809326 \n",
      "Epoch 61: Validation loss: 0.665848433971405 Best loss: 0.665848433971405 Accuracy: 0.7733333110809326 \n",
      "Epoch 62: Validation loss: 0.6618235111236572 Best loss: 0.6618235111236572 Accuracy: 0.7733333110809326 \n",
      "Epoch 63: Validation loss: 0.6579217314720154 Best loss: 0.6579217314720154 Accuracy: 0.7733333110809326 \n",
      "Epoch 64: Validation loss: 0.6541372537612915 Best loss: 0.6541372537612915 Accuracy: 0.7866666316986084 \n",
      "Epoch 65: Validation loss: 0.6504644751548767 Best loss: 0.6504644751548767 Accuracy: 0.7866666316986084 \n",
      "Epoch 66: Validation loss: 0.6468982100486755 Best loss: 0.6468982100486755 Accuracy: 0.7866666316986084 \n",
      "Epoch 67: Validation loss: 0.6434333324432373 Best loss: 0.6434333324432373 Accuracy: 0.7866666316986084 \n",
      "Epoch 68: Validation loss: 0.6400654315948486 Best loss: 0.6400654315948486 Accuracy: 0.7866666316986084 \n",
      "Epoch 69: Validation loss: 0.6367899179458618 Best loss: 0.6367899179458618 Accuracy: 0.7866666316986084 \n",
      "Epoch 70: Validation loss: 0.6336029171943665 Best loss: 0.6336029171943665 Accuracy: 0.7933332920074463 \n",
      "Epoch 71: Validation loss: 0.6305002570152283 Best loss: 0.6305002570152283 Accuracy: 0.7933332920074463 \n",
      "Epoch 72: Validation loss: 0.6274784207344055 Best loss: 0.6274784207344055 Accuracy: 0.7933332920074463 \n",
      "Epoch 73: Validation loss: 0.6245340704917908 Best loss: 0.6245340704917908 Accuracy: 0.7933332920074463 \n",
      "Epoch 74: Validation loss: 0.6216636300086975 Best loss: 0.6216636300086975 Accuracy: 0.7933332920074463 \n",
      "Epoch 75: Validation loss: 0.6188640594482422 Best loss: 0.6188640594482422 Accuracy: 0.7933332920074463 \n",
      "Epoch 76: Validation loss: 0.6161326169967651 Best loss: 0.6161326169967651 Accuracy: 0.7933332920074463 \n",
      "Epoch 77: Validation loss: 0.6134665608406067 Best loss: 0.6134665608406067 Accuracy: 0.7933332920074463 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Validation loss: 0.6108630299568176 Best loss: 0.6108630299568176 Accuracy: 0.7999999523162842 \n",
      "Epoch 79: Validation loss: 0.6083198189735413 Best loss: 0.6083198189735413 Accuracy: 0.7999999523162842 \n",
      "Epoch 80: Validation loss: 0.6058343648910522 Best loss: 0.6058343648910522 Accuracy: 0.8066666126251221 \n",
      "Epoch 81: Validation loss: 0.6034047603607178 Best loss: 0.6034047603607178 Accuracy: 0.8066666126251221 \n",
      "Epoch 82: Validation loss: 0.6010286211967468 Best loss: 0.6010286211967468 Accuracy: 0.8199999928474426 \n",
      "Epoch 83: Validation loss: 0.5987042188644409 Best loss: 0.5987042188644409 Accuracy: 0.8199999928474426 \n",
      "Epoch 84: Validation loss: 0.5964294672012329 Best loss: 0.5964294672012329 Accuracy: 0.8199999928474426 \n",
      "Epoch 85: Validation loss: 0.5942028760910034 Best loss: 0.5942028760910034 Accuracy: 0.8199999928474426 \n",
      "Epoch 86: Validation loss: 0.5920225381851196 Best loss: 0.5920225381851196 Accuracy: 0.8199999928474426 \n",
      "Epoch 87: Validation loss: 0.5898870229721069 Best loss: 0.5898870229721069 Accuracy: 0.8199999928474426 \n",
      "Epoch 88: Validation loss: 0.587794840335846 Best loss: 0.587794840335846 Accuracy: 0.8199999928474426 \n",
      "Epoch 89: Validation loss: 0.5857445001602173 Best loss: 0.5857445001602173 Accuracy: 0.8199999928474426 \n",
      "Epoch 90: Validation loss: 0.5837346911430359 Best loss: 0.5837346911430359 Accuracy: 0.8199999928474426 \n",
      "Epoch 91: Validation loss: 0.5817643404006958 Best loss: 0.5817643404006958 Accuracy: 0.8199999928474426 \n",
      "Epoch 92: Validation loss: 0.5798319578170776 Best loss: 0.5798319578170776 Accuracy: 0.8199999928474426 \n",
      "Epoch 93: Validation loss: 0.5779364705085754 Best loss: 0.5779364705085754 Accuracy: 0.8199999928474426 \n",
      "Epoch 94: Validation loss: 0.576076865196228 Best loss: 0.576076865196228 Accuracy: 0.8199999928474426 \n",
      "Epoch 95: Validation loss: 0.5742521286010742 Best loss: 0.5742521286010742 Accuracy: 0.8199999928474426 \n",
      "Epoch 96: Validation loss: 0.5724612474441528 Best loss: 0.5724612474441528 Accuracy: 0.8199999928474426 \n",
      "Epoch 97: Validation loss: 0.5707032680511475 Best loss: 0.5707032680511475 Accuracy: 0.8199999928474426 \n",
      "Epoch 98: Validation loss: 0.5689772367477417 Best loss: 0.5689772367477417 Accuracy: 0.8199999928474426 \n",
      "Epoch 99: Validation loss: 0.5672824382781982 Best loss: 0.5672824382781982 Accuracy: 0.8199999928474426 \n",
      "Epoch 100: Validation loss: 0.5656180381774902 Best loss: 0.5656180381774902 Accuracy: 0.8199999928474426 \n",
      "Epoch 101: Validation loss: 0.5639832019805908 Best loss: 0.5639832019805908 Accuracy: 0.8199999928474426 \n",
      "Epoch 102: Validation loss: 0.5623772144317627 Best loss: 0.5623772144317627 Accuracy: 0.8199999928474426 \n",
      "Epoch 103: Validation loss: 0.5607994198799133 Best loss: 0.5607994198799133 Accuracy: 0.8199999928474426 \n",
      "Epoch 104: Validation loss: 0.5592488646507263 Best loss: 0.5592488646507263 Accuracy: 0.8199999928474426 \n",
      "Epoch 105: Validation loss: 0.5577251315116882 Best loss: 0.5577251315116882 Accuracy: 0.8199999928474426 \n",
      "Epoch 106: Validation loss: 0.5562276244163513 Best loss: 0.5562276244163513 Accuracy: 0.8199999928474426 \n",
      "Epoch 107: Validation loss: 0.5547555685043335 Best loss: 0.5547555685043335 Accuracy: 0.8199999928474426 \n",
      "Epoch 108: Validation loss: 0.553308367729187 Best loss: 0.553308367729187 Accuracy: 0.8199999928474426 \n",
      "Epoch 109: Validation loss: 0.5518856644630432 Best loss: 0.5518856644630432 Accuracy: 0.8199999928474426 \n",
      "Epoch 110: Validation loss: 0.55048668384552 Best loss: 0.55048668384552 Accuracy: 0.8199999928474426 \n",
      "Epoch 111: Validation loss: 0.549111008644104 Best loss: 0.549111008644104 Accuracy: 0.8199999928474426 \n",
      "Epoch 112: Validation loss: 0.5477580428123474 Best loss: 0.5477580428123474 Accuracy: 0.8199999928474426 \n",
      "Epoch 113: Validation loss: 0.5464273691177368 Best loss: 0.5464273691177368 Accuracy: 0.8199999928474426 \n",
      "Epoch 114: Validation loss: 0.5451184511184692 Best loss: 0.5451184511184692 Accuracy: 0.8199999928474426 \n",
      "Epoch 115: Validation loss: 0.5438308119773865 Best loss: 0.5438308119773865 Accuracy: 0.8199999928474426 \n",
      "Epoch 116: Validation loss: 0.5425640940666199 Best loss: 0.5425640940666199 Accuracy: 0.8199999928474426 \n",
      "Epoch 117: Validation loss: 0.5413177013397217 Best loss: 0.5413177013397217 Accuracy: 0.8199999928474426 \n",
      "Epoch 118: Validation loss: 0.5400912761688232 Best loss: 0.5400912761688232 Accuracy: 0.8266666531562805 \n",
      "Epoch 119: Validation loss: 0.5388844013214111 Best loss: 0.5388844013214111 Accuracy: 0.8333333134651184 \n",
      "Epoch 120: Validation loss: 0.5376967191696167 Best loss: 0.5376967191696167 Accuracy: 0.8333333134651184 \n",
      "Epoch 121: Validation loss: 0.5365278124809265 Best loss: 0.5365278124809265 Accuracy: 0.8333333134651184 \n",
      "Epoch 122: Validation loss: 0.5353771448135376 Best loss: 0.5353771448135376 Accuracy: 0.8333333134651184 \n",
      "Epoch 123: Validation loss: 0.5342445373535156 Best loss: 0.5342445373535156 Accuracy: 0.8333333134651184 \n",
      "Epoch 124: Validation loss: 0.5331295728683472 Best loss: 0.5331295728683472 Accuracy: 0.8333333134651184 \n",
      "Epoch 125: Validation loss: 0.5320318937301636 Best loss: 0.5320318937301636 Accuracy: 0.8333333134651184 \n",
      "Epoch 126: Validation loss: 0.5309511423110962 Best loss: 0.5309511423110962 Accuracy: 0.8333333134651184 \n",
      "Epoch 127: Validation loss: 0.5298870205879211 Best loss: 0.5298870205879211 Accuracy: 0.8333333134651184 \n",
      "Epoch 128: Validation loss: 0.528839111328125 Best loss: 0.528839111328125 Accuracy: 0.8333333134651184 \n",
      "Epoch 129: Validation loss: 0.5278071761131287 Best loss: 0.5278071761131287 Accuracy: 0.8333333134651184 \n",
      "Epoch 130: Validation loss: 0.5267909169197083 Best loss: 0.5267909169197083 Accuracy: 0.8333333134651184 \n",
      "Epoch 131: Validation loss: 0.5257899761199951 Best loss: 0.5257899761199951 Accuracy: 0.8333333134651184 \n",
      "Epoch 132: Validation loss: 0.5248041152954102 Best loss: 0.5248041152954102 Accuracy: 0.8333333134651184 \n",
      "Epoch 133: Validation loss: 0.5238330960273743 Best loss: 0.5238330960273743 Accuracy: 0.8333333134651184 \n",
      "Epoch 134: Validation loss: 0.522876501083374 Best loss: 0.522876501083374 Accuracy: 0.8333333134651184 \n",
      "Epoch 135: Validation loss: 0.5219340920448303 Best loss: 0.5219340920448303 Accuracy: 0.8333333134651184 \n",
      "Epoch 136: Validation loss: 0.5210056900978088 Best loss: 0.5210056900978088 Accuracy: 0.8399999737739563 \n",
      "Epoch 137: Validation loss: 0.5200910568237305 Best loss: 0.5200910568237305 Accuracy: 0.8399999737739563 \n",
      "Epoch 138: Validation loss: 0.5191897749900818 Best loss: 0.5191897749900818 Accuracy: 0.8400000333786011 \n",
      "Epoch 139: Validation loss: 0.5183017253875732 Best loss: 0.5183017253875732 Accuracy: 0.8399999737739563 \n",
      "Epoch 140: Validation loss: 0.5174267292022705 Best loss: 0.5174267292022705 Accuracy: 0.846666693687439 \n",
      "Epoch 141: Validation loss: 0.5165644884109497 Best loss: 0.5165644884109497 Accuracy: 0.846666693687439 \n",
      "Epoch 142: Validation loss: 0.515714704990387 Best loss: 0.515714704990387 Accuracy: 0.846666693687439 \n",
      "Epoch 143: Validation loss: 0.5148772597312927 Best loss: 0.5148772597312927 Accuracy: 0.846666693687439 \n",
      "Epoch 144: Validation loss: 0.5140519142150879 Best loss: 0.5140519142150879 Accuracy: 0.8466666340827942 \n",
      "Epoch 145: Validation loss: 0.5132384896278381 Best loss: 0.5132384896278381 Accuracy: 0.846666693687439 \n",
      "Epoch 146: Validation loss: 0.5124366879463196 Best loss: 0.5124366879463196 Accuracy: 0.846666693687439 \n",
      "Epoch 147: Validation loss: 0.5116463303565979 Best loss: 0.5116463303565979 Accuracy: 0.846666693687439 \n",
      "Epoch 148: Validation loss: 0.5108673572540283 Best loss: 0.5108673572540283 Accuracy: 0.846666693687439 \n",
      "Epoch 149: Validation loss: 0.5100994110107422 Best loss: 0.5100994110107422 Accuracy: 0.846666693687439 \n",
      "Epoch 150: Validation loss: 0.5093424916267395 Best loss: 0.5093424916267395 Accuracy: 0.846666693687439 \n",
      "Epoch 151: Validation loss: 0.5085961818695068 Best loss: 0.5085961818695068 Accuracy: 0.846666693687439 \n",
      "Epoch 152: Validation loss: 0.5078604817390442 Best loss: 0.5078604817390442 Accuracy: 0.846666693687439 \n",
      "Epoch 153: Validation loss: 0.507135272026062 Best loss: 0.507135272026062 Accuracy: 0.846666693687439 \n",
      "Epoch 154: Validation loss: 0.5064202547073364 Best loss: 0.5064202547073364 Accuracy: 0.846666693687439 \n",
      "Epoch 155: Validation loss: 0.5057151913642883 Best loss: 0.5057151913642883 Accuracy: 0.846666693687439 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156: Validation loss: 0.5050200819969177 Best loss: 0.5050200819969177 Accuracy: 0.846666693687439 \n",
      "Epoch 157: Validation loss: 0.5043348073959351 Best loss: 0.5043348073959351 Accuracy: 0.8466666340827942 \n",
      "Epoch 158: Validation loss: 0.5036590695381165 Best loss: 0.5036590695381165 Accuracy: 0.846666693687439 \n",
      "Epoch 159: Validation loss: 0.5029927492141724 Best loss: 0.5029927492141724 Accuracy: 0.846666693687439 \n",
      "Epoch 160: Validation loss: 0.5023357272148132 Best loss: 0.5023357272148132 Accuracy: 0.846666693687439 \n",
      "Epoch 161: Validation loss: 0.5016879439353943 Best loss: 0.5016879439353943 Accuracy: 0.846666693687439 \n",
      "Epoch 162: Validation loss: 0.5010491609573364 Best loss: 0.5010491609573364 Accuracy: 0.846666693687439 \n",
      "Epoch 163: Validation loss: 0.5004191994667053 Best loss: 0.5004191994667053 Accuracy: 0.846666693687439 \n",
      "Epoch 164: Validation loss: 0.49979811906814575 Best loss: 0.49979811906814575 Accuracy: 0.846666693687439 \n",
      "Epoch 165: Validation loss: 0.49918556213378906 Best loss: 0.49918556213378906 Accuracy: 0.846666693687439 \n",
      "Epoch 166: Validation loss: 0.4985814094543457 Best loss: 0.4985814094543457 Accuracy: 0.8466666340827942 \n",
      "Epoch 167: Validation loss: 0.4979858100414276 Best loss: 0.4979858100414276 Accuracy: 0.846666693687439 \n",
      "Epoch 168: Validation loss: 0.49739840626716614 Best loss: 0.49739840626716614 Accuracy: 0.8466666340827942 \n",
      "Epoch 169: Validation loss: 0.4968191385269165 Best loss: 0.4968191385269165 Accuracy: 0.846666693687439 \n",
      "Epoch 170: Validation loss: 0.49624788761138916 Best loss: 0.49624788761138916 Accuracy: 0.846666693687439 \n",
      "Epoch 171: Validation loss: 0.49568456411361694 Best loss: 0.49568456411361694 Accuracy: 0.846666693687439 \n",
      "Epoch 172: Validation loss: 0.4951289892196655 Best loss: 0.4951289892196655 Accuracy: 0.8533333539962769 \n",
      "Epoch 173: Validation loss: 0.4945811629295349 Best loss: 0.4945811629295349 Accuracy: 0.8533333539962769 \n",
      "Epoch 174: Validation loss: 0.494040846824646 Best loss: 0.494040846824646 Accuracy: 0.8533333539962769 \n",
      "Epoch 175: Validation loss: 0.4935080409049988 Best loss: 0.4935080409049988 Accuracy: 0.8533333539962769 \n",
      "Epoch 176: Validation loss: 0.4929825961589813 Best loss: 0.4929825961589813 Accuracy: 0.8533333539962769 \n",
      "Epoch 177: Validation loss: 0.4924643635749817 Best loss: 0.4924643635749817 Accuracy: 0.8533333539962769 \n",
      "Epoch 178: Validation loss: 0.49195337295532227 Best loss: 0.49195337295532227 Accuracy: 0.8533333539962769 \n",
      "Epoch 179: Validation loss: 0.49144935607910156 Best loss: 0.49144935607910156 Accuracy: 0.8533333539962769 \n",
      "Epoch 180: Validation loss: 0.49095243215560913 Best loss: 0.49095243215560913 Accuracy: 0.8533333539962769 \n",
      "Epoch 181: Validation loss: 0.4904623031616211 Best loss: 0.4904623031616211 Accuracy: 0.8533333539962769 \n",
      "Epoch 182: Validation loss: 0.4899790287017822 Best loss: 0.4899790287017822 Accuracy: 0.8533333539962769 \n",
      "Epoch 183: Validation loss: 0.4895023703575134 Best loss: 0.4895023703575134 Accuracy: 0.8533333539962769 \n",
      "Epoch 184: Validation loss: 0.4890323579311371 Best loss: 0.4890323579311371 Accuracy: 0.8533333539962769 \n",
      "Epoch 185: Validation loss: 0.48856890201568604 Best loss: 0.48856890201568604 Accuracy: 0.8533333539962769 \n",
      "Epoch 186: Validation loss: 0.4881119132041931 Best loss: 0.4881119132041931 Accuracy: 0.8533333539962769 \n",
      "Epoch 187: Validation loss: 0.4876611828804016 Best loss: 0.4876611828804016 Accuracy: 0.8533333539962769 \n",
      "Epoch 188: Validation loss: 0.4872168004512787 Best loss: 0.4872168004512787 Accuracy: 0.8533333539962769 \n",
      "Epoch 189: Validation loss: 0.4867785573005676 Best loss: 0.4867785573005676 Accuracy: 0.8533332943916321 \n",
      "Epoch 190: Validation loss: 0.48634642362594604 Best loss: 0.48634642362594604 Accuracy: 0.8533333539962769 \n",
      "Epoch 191: Validation loss: 0.48592036962509155 Best loss: 0.48592036962509155 Accuracy: 0.8533333539962769 \n",
      "Epoch 192: Validation loss: 0.4855002164840698 Best loss: 0.4855002164840698 Accuracy: 0.8533333539962769 \n",
      "Epoch 193: Validation loss: 0.48508599400520325 Best loss: 0.48508599400520325 Accuracy: 0.8533333539962769 \n",
      "Epoch 194: Validation loss: 0.4846775531768799 Best loss: 0.4846775531768799 Accuracy: 0.8533333539962769 \n",
      "Epoch 195: Validation loss: 0.48427486419677734 Best loss: 0.48427486419677734 Accuracy: 0.8533333539962769 \n",
      "Epoch 196: Validation loss: 0.4838777780532837 Best loss: 0.4838777780532837 Accuracy: 0.8533332943916321 \n",
      "Epoch 197: Validation loss: 0.48348644375801086 Best loss: 0.48348644375801086 Accuracy: 0.8533332943916321 \n",
      "Epoch 198: Validation loss: 0.48310044407844543 Best loss: 0.48310044407844543 Accuracy: 0.8533333539962769 \n",
      "Epoch 199: Validation loss: 0.4827199876308441 Best loss: 0.4827199876308441 Accuracy: 0.8533333539962769 \n",
      "Epoch 200: Validation loss: 0.4823448956012726 Best loss: 0.4823448956012726 Accuracy: 0.8533333539962769 \n",
      "Epoch 201: Validation loss: 0.4819751977920532 Best loss: 0.4819751977920532 Accuracy: 0.8533332943916321 \n",
      "Epoch 202: Validation loss: 0.48161062598228455 Best loss: 0.48161062598228455 Accuracy: 0.8533333539962769 \n",
      "Epoch 203: Validation loss: 0.4812513589859009 Best loss: 0.4812513589859009 Accuracy: 0.8533333539962769 \n",
      "Epoch 204: Validation loss: 0.4808971583843231 Best loss: 0.4808971583843231 Accuracy: 0.8533333539962769 \n",
      "Epoch 205: Validation loss: 0.48054805397987366 Best loss: 0.48054805397987366 Accuracy: 0.8466666340827942 \n",
      "Epoch 206: Validation loss: 0.48020392656326294 Best loss: 0.48020392656326294 Accuracy: 0.8466666340827942 \n",
      "Epoch 207: Validation loss: 0.47986477613449097 Best loss: 0.47986477613449097 Accuracy: 0.8466666340827942 \n",
      "Epoch 208: Validation loss: 0.4795304834842682 Best loss: 0.4795304834842682 Accuracy: 0.8466666340827942 \n",
      "Epoch 209: Validation loss: 0.4792010188102722 Best loss: 0.4792010188102722 Accuracy: 0.8466666340827942 \n",
      "Epoch 210: Validation loss: 0.47887635231018066 Best loss: 0.47887635231018066 Accuracy: 0.8466666340827942 \n",
      "Epoch 211: Validation loss: 0.47855639457702637 Best loss: 0.47855639457702637 Accuracy: 0.8466666340827942 \n",
      "Epoch 212: Validation loss: 0.4782411754131317 Best loss: 0.4782411754131317 Accuracy: 0.846666693687439 \n",
      "Epoch 213: Validation loss: 0.4779304563999176 Best loss: 0.4779304563999176 Accuracy: 0.8466666340827942 \n",
      "Epoch 214: Validation loss: 0.4776242971420288 Best loss: 0.4776242971420288 Accuracy: 0.8466666340827942 \n",
      "Epoch 215: Validation loss: 0.47732263803482056 Best loss: 0.47732263803482056 Accuracy: 0.846666693687439 \n",
      "Epoch 216: Validation loss: 0.47702544927597046 Best loss: 0.47702544927597046 Accuracy: 0.8466666340827942 \n",
      "Epoch 217: Validation loss: 0.4767325520515442 Best loss: 0.4767325520515442 Accuracy: 0.846666693687439 \n",
      "Epoch 218: Validation loss: 0.47644415497779846 Best loss: 0.47644415497779846 Accuracy: 0.8466666340827942 \n",
      "Epoch 219: Validation loss: 0.4761599898338318 Best loss: 0.4761599898338318 Accuracy: 0.8466666340827942 \n",
      "Epoch 220: Validation loss: 0.4758800268173218 Best loss: 0.4758800268173218 Accuracy: 0.8466666340827942 \n",
      "Epoch 221: Validation loss: 0.47560426592826843 Best loss: 0.47560426592826843 Accuracy: 0.8466666340827942 \n",
      "Epoch 222: Validation loss: 0.47533276677131653 Best loss: 0.47533276677131653 Accuracy: 0.8466666340827942 \n",
      "Epoch 223: Validation loss: 0.4750652611255646 Best loss: 0.4750652611255646 Accuracy: 0.846666693687439 \n",
      "Epoch 224: Validation loss: 0.4748018682003021 Best loss: 0.4748018682003021 Accuracy: 0.8466666340827942 \n",
      "Epoch 225: Validation loss: 0.47454243898391724 Best loss: 0.47454243898391724 Accuracy: 0.8466666340827942 \n",
      "Epoch 226: Validation loss: 0.4742869734764099 Best loss: 0.4742869734764099 Accuracy: 0.8466666340827942 \n",
      "Epoch 227: Validation loss: 0.47403547167778015 Best loss: 0.47403547167778015 Accuracy: 0.8466666340827942 \n",
      "Epoch 228: Validation loss: 0.473787784576416 Best loss: 0.473787784576416 Accuracy: 0.8466666340827942 \n",
      "Epoch 229: Validation loss: 0.47354400157928467 Best loss: 0.47354400157928467 Accuracy: 0.8466666340827942 \n",
      "Epoch 230: Validation loss: 0.47330397367477417 Best loss: 0.47330397367477417 Accuracy: 0.8466666340827942 \n",
      "Epoch 231: Validation loss: 0.47306767106056213 Best loss: 0.47306767106056213 Accuracy: 0.8466666340827942 \n",
      "Epoch 232: Validation loss: 0.47283512353897095 Best loss: 0.47283512353897095 Accuracy: 0.8466666340827942 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233: Validation loss: 0.47260624170303345 Best loss: 0.47260624170303345 Accuracy: 0.8466666340827942 \n",
      "Epoch 234: Validation loss: 0.4723809063434601 Best loss: 0.4723809063434601 Accuracy: 0.8466666340827942 \n",
      "Epoch 235: Validation loss: 0.4721592366695404 Best loss: 0.4721592366695404 Accuracy: 0.8466666340827942 \n",
      "Epoch 236: Validation loss: 0.47194114327430725 Best loss: 0.47194114327430725 Accuracy: 0.8466666340827942 \n",
      "Epoch 237: Validation loss: 0.47172653675079346 Best loss: 0.47172653675079346 Accuracy: 0.8466666340827942 \n",
      "Epoch 238: Validation loss: 0.47151532769203186 Best loss: 0.47151532769203186 Accuracy: 0.8466666340827942 \n",
      "Epoch 239: Validation loss: 0.471307635307312 Best loss: 0.471307635307312 Accuracy: 0.8466666340827942 \n",
      "Epoch 240: Validation loss: 0.4711032509803772 Best loss: 0.4711032509803772 Accuracy: 0.8466666340827942 \n",
      "Epoch 241: Validation loss: 0.47090232372283936 Best loss: 0.47090232372283936 Accuracy: 0.8466666340827942 \n",
      "Epoch 242: Validation loss: 0.47070473432540894 Best loss: 0.47070473432540894 Accuracy: 0.8466666340827942 \n",
      "Epoch 243: Validation loss: 0.4705103039741516 Best loss: 0.4705103039741516 Accuracy: 0.8466666340827942 \n",
      "Epoch 244: Validation loss: 0.4703192710876465 Best loss: 0.4703192710876465 Accuracy: 0.8466666340827942 \n",
      "Epoch 245: Validation loss: 0.47013136744499207 Best loss: 0.47013136744499207 Accuracy: 0.8466666340827942 \n",
      "Epoch 246: Validation loss: 0.4699467420578003 Best loss: 0.4699467420578003 Accuracy: 0.8466666340827942 \n",
      "Epoch 247: Validation loss: 0.4697651267051697 Best loss: 0.4697651267051697 Accuracy: 0.8466666340827942 \n",
      "Epoch 248: Validation loss: 0.4695867896080017 Best loss: 0.4695867896080017 Accuracy: 0.8466666340827942 \n",
      "Epoch 249: Validation loss: 0.4694114327430725 Best loss: 0.4694114327430725 Accuracy: 0.8466666340827942 \n",
      "Epoch 250: Validation loss: 0.46923914551734924 Best loss: 0.46923914551734924 Accuracy: 0.8466666340827942 \n",
      "Epoch 251: Validation loss: 0.46906986832618713 Best loss: 0.46906986832618713 Accuracy: 0.846666693687439 \n",
      "Epoch 252: Validation loss: 0.4689035713672638 Best loss: 0.4689035713672638 Accuracy: 0.8466666340827942 \n",
      "Epoch 253: Validation loss: 0.468740314245224 Best loss: 0.468740314245224 Accuracy: 0.8466666340827942 \n",
      "Epoch 254: Validation loss: 0.4685799479484558 Best loss: 0.4685799479484558 Accuracy: 0.8466666340827942 \n",
      "Epoch 255: Validation loss: 0.4684223532676697 Best loss: 0.4684223532676697 Accuracy: 0.8466666340827942 \n",
      "Epoch 256: Validation loss: 0.4682677090167999 Best loss: 0.4682677090167999 Accuracy: 0.8466666340827942 \n",
      "Epoch 257: Validation loss: 0.4681159257888794 Best loss: 0.4681159257888794 Accuracy: 0.8466666340827942 \n",
      "Epoch 258: Validation loss: 0.4679669737815857 Best loss: 0.4679669737815857 Accuracy: 0.8466666340827942 \n",
      "Epoch 259: Validation loss: 0.4678207337856293 Best loss: 0.4678207337856293 Accuracy: 0.8466666340827942 \n",
      "Epoch 260: Validation loss: 0.4676772654056549 Best loss: 0.4676772654056549 Accuracy: 0.8466666340827942 \n",
      "Epoch 261: Validation loss: 0.4675365090370178 Best loss: 0.4675365090370178 Accuracy: 0.8466666340827942 \n",
      "Epoch 262: Validation loss: 0.46739843487739563 Best loss: 0.46739843487739563 Accuracy: 0.8466666340827942 \n",
      "Epoch 263: Validation loss: 0.46726304292678833 Best loss: 0.46726304292678833 Accuracy: 0.8466666340827942 \n",
      "Epoch 264: Validation loss: 0.4671303629875183 Best loss: 0.4671303629875183 Accuracy: 0.8466666340827942 \n",
      "Epoch 265: Validation loss: 0.46700018644332886 Best loss: 0.46700018644332886 Accuracy: 0.8466666340827942 \n",
      "Epoch 266: Validation loss: 0.4668726325035095 Best loss: 0.4668726325035095 Accuracy: 0.8466666340827942 \n",
      "Epoch 267: Validation loss: 0.46674761176109314 Best loss: 0.46674761176109314 Accuracy: 0.8466666340827942 \n",
      "Epoch 268: Validation loss: 0.4666251540184021 Best loss: 0.4666251540184021 Accuracy: 0.8466666340827942 \n",
      "Epoch 269: Validation loss: 0.46650516986846924 Best loss: 0.46650516986846924 Accuracy: 0.8466666340827942 \n",
      "Epoch 270: Validation loss: 0.46638768911361694 Best loss: 0.46638768911361694 Accuracy: 0.8466666340827942 \n",
      "Epoch 271: Validation loss: 0.4662726819515228 Best loss: 0.4662726819515228 Accuracy: 0.8400000333786011 \n",
      "Epoch 272: Validation loss: 0.4661600887775421 Best loss: 0.4661600887775421 Accuracy: 0.8399999737739563 \n",
      "Epoch 273: Validation loss: 0.4660499095916748 Best loss: 0.4660499095916748 Accuracy: 0.8399999737739563 \n",
      "Epoch 274: Validation loss: 0.46594205498695374 Best loss: 0.46594205498695374 Accuracy: 0.8399999737739563 \n",
      "Epoch 275: Validation loss: 0.4658365845680237 Best loss: 0.4658365845680237 Accuracy: 0.8399999737739563 \n",
      "Epoch 276: Validation loss: 0.46573346853256226 Best loss: 0.46573346853256226 Accuracy: 0.8399999737739563 \n",
      "Epoch 277: Validation loss: 0.4656326174736023 Best loss: 0.4656326174736023 Accuracy: 0.8399999737739563 \n",
      "Epoch 278: Validation loss: 0.4655340909957886 Best loss: 0.4655340909957886 Accuracy: 0.8399999737739563 \n",
      "Epoch 279: Validation loss: 0.46543774008750916 Best loss: 0.46543774008750916 Accuracy: 0.8399999737739563 \n",
      "Epoch 280: Validation loss: 0.4653436541557312 Best loss: 0.4653436541557312 Accuracy: 0.8400000333786011 \n",
      "Epoch 281: Validation loss: 0.4652518928050995 Best loss: 0.4652518928050995 Accuracy: 0.8399999737739563 \n",
      "Epoch 282: Validation loss: 0.4651622176170349 Best loss: 0.4651622176170349 Accuracy: 0.8399999737739563 \n",
      "Epoch 283: Validation loss: 0.46507471799850464 Best loss: 0.46507471799850464 Accuracy: 0.8399999737739563 \n",
      "Epoch 284: Validation loss: 0.4649895131587982 Best loss: 0.4649895131587982 Accuracy: 0.8399999737739563 \n",
      "Epoch 285: Validation loss: 0.4649062752723694 Best loss: 0.4649062752723694 Accuracy: 0.8399999737739563 \n",
      "Epoch 286: Validation loss: 0.4648251235485077 Best loss: 0.4648251235485077 Accuracy: 0.8399999737739563 \n",
      "Epoch 287: Validation loss: 0.4647461175918579 Best loss: 0.4647461175918579 Accuracy: 0.8399999737739563 \n",
      "Epoch 288: Validation loss: 0.4646691679954529 Best loss: 0.4646691679954529 Accuracy: 0.8399999737739563 \n",
      "Epoch 289: Validation loss: 0.4645942449569702 Best loss: 0.4645942449569702 Accuracy: 0.8399999737739563 \n",
      "Epoch 290: Validation loss: 0.4645213484764099 Best loss: 0.4645213484764099 Accuracy: 0.8399999737739563 \n",
      "Epoch 291: Validation loss: 0.464450478553772 Best loss: 0.464450478553772 Accuracy: 0.8399999737739563 \n",
      "Epoch 292: Validation loss: 0.46438151597976685 Best loss: 0.46438151597976685 Accuracy: 0.8399999737739563 \n",
      "Epoch 293: Validation loss: 0.4643145799636841 Best loss: 0.4643145799636841 Accuracy: 0.8399999737739563 \n",
      "Epoch 294: Validation loss: 0.46424955129623413 Best loss: 0.46424955129623413 Accuracy: 0.8399999737739563 \n",
      "Epoch 295: Validation loss: 0.46418648958206177 Best loss: 0.46418648958206177 Accuracy: 0.8399999737739563 \n",
      "Epoch 296: Validation loss: 0.46412527561187744 Best loss: 0.46412527561187744 Accuracy: 0.8399999737739563 \n",
      "Epoch 297: Validation loss: 0.46406593918800354 Best loss: 0.46406593918800354 Accuracy: 0.8399999737739563 \n",
      "Epoch 298: Validation loss: 0.46400848031044006 Best loss: 0.46400848031044006 Accuracy: 0.8399999737739563 \n",
      "Epoch 299: Validation loss: 0.463952898979187 Best loss: 0.463952898979187 Accuracy: 0.8399999737739563 \n",
      "Epoch 300: Validation loss: 0.4638991057872772 Best loss: 0.4638991057872772 Accuracy: 0.8400000333786011 \n",
      "Epoch 301: Validation loss: 0.4638471007347107 Best loss: 0.4638471007347107 Accuracy: 0.8399999737739563 \n",
      "Epoch 302: Validation loss: 0.4637969136238098 Best loss: 0.4637969136238098 Accuracy: 0.8399999737739563 \n",
      "Epoch 303: Validation loss: 0.4637484550476074 Best loss: 0.4637484550476074 Accuracy: 0.8399999737739563 \n",
      "Epoch 304: Validation loss: 0.4637017250061035 Best loss: 0.4637017250061035 Accuracy: 0.8399999737739563 \n",
      "Epoch 305: Validation loss: 0.46365678310394287 Best loss: 0.46365678310394287 Accuracy: 0.8399999737739563 \n",
      "Epoch 306: Validation loss: 0.4636135399341583 Best loss: 0.4636135399341583 Accuracy: 0.8399999737739563 \n",
      "Epoch 307: Validation loss: 0.4635719656944275 Best loss: 0.4635719656944275 Accuracy: 0.8399999737739563 \n",
      "Epoch 308: Validation loss: 0.46353214979171753 Best loss: 0.46353214979171753 Accuracy: 0.8399999737739563 \n",
      "Epoch 309: Validation loss: 0.46349385380744934 Best loss: 0.46349385380744934 Accuracy: 0.8399999737739563 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310: Validation loss: 0.46345725655555725 Best loss: 0.46345725655555725 Accuracy: 0.8399999737739563 \n",
      "Epoch 311: Validation loss: 0.4634222686290741 Best loss: 0.4634222686290741 Accuracy: 0.8399999737739563 \n",
      "Epoch 312: Validation loss: 0.46338894963264465 Best loss: 0.46338894963264465 Accuracy: 0.8399999737739563 \n",
      "Epoch 313: Validation loss: 0.46335726976394653 Best loss: 0.46335726976394653 Accuracy: 0.8400000333786011 \n",
      "Epoch 314: Validation loss: 0.4633270502090454 Best loss: 0.4633270502090454 Accuracy: 0.8399999737739563 \n",
      "Epoch 315: Validation loss: 0.4632984399795532 Best loss: 0.4632984399795532 Accuracy: 0.8399999737739563 \n",
      "Epoch 316: Validation loss: 0.4632714092731476 Best loss: 0.4632714092731476 Accuracy: 0.8399999737739563 \n",
      "Epoch 317: Validation loss: 0.46324580907821655 Best loss: 0.46324580907821655 Accuracy: 0.8399999737739563 \n",
      "Epoch 318: Validation loss: 0.46322181820869446 Best loss: 0.46322181820869446 Accuracy: 0.846666693687439 \n",
      "Epoch 319: Validation loss: 0.46319931745529175 Best loss: 0.46319931745529175 Accuracy: 0.846666693687439 \n",
      "Epoch 320: Validation loss: 0.46317821741104126 Best loss: 0.46317821741104126 Accuracy: 0.846666693687439 \n",
      "Epoch 321: Validation loss: 0.46315860748291016 Best loss: 0.46315860748291016 Accuracy: 0.846666693687439 \n",
      "Epoch 322: Validation loss: 0.46314048767089844 Best loss: 0.46314048767089844 Accuracy: 0.846666693687439 \n",
      "Epoch 323: Validation loss: 0.4631238281726837 Best loss: 0.4631238281726837 Accuracy: 0.846666693687439 \n",
      "Epoch 324: Validation loss: 0.46310847997665405 Best loss: 0.46310847997665405 Accuracy: 0.846666693687439 \n",
      "Epoch 325: Validation loss: 0.4630946218967438 Best loss: 0.4630946218967438 Accuracy: 0.846666693687439 \n",
      "Epoch 326: Validation loss: 0.46308210492134094 Best loss: 0.46308210492134094 Accuracy: 0.846666693687439 \n",
      "Epoch 327: Validation loss: 0.4630710184574127 Best loss: 0.4630710184574127 Accuracy: 0.846666693687439 \n",
      "Epoch 328: Validation loss: 0.46306121349334717 Best loss: 0.46306121349334717 Accuracy: 0.846666693687439 \n",
      "Epoch 329: Validation loss: 0.46305280923843384 Best loss: 0.46305280923843384 Accuracy: 0.8466666340827942 \n",
      "Epoch 330: Validation loss: 0.46304574608802795 Best loss: 0.46304574608802795 Accuracy: 0.846666693687439 \n",
      "Epoch 331: Validation loss: 0.46303999423980713 Best loss: 0.46303999423980713 Accuracy: 0.8466666340827942 \n",
      "Epoch 332: Validation loss: 0.4630354642868042 Best loss: 0.4630354642868042 Accuracy: 0.846666693687439 \n",
      "Epoch 333: Validation loss: 0.4630323052406311 Best loss: 0.4630323052406311 Accuracy: 0.846666693687439 \n",
      "Epoch 334: Validation loss: 0.4630304276943207 Best loss: 0.4630304276943207 Accuracy: 0.846666693687439 \n",
      "Epoch 335: Validation loss: 0.46302980184555054 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 336: Validation loss: 0.4630303680896759 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 337: Validation loss: 0.46303224563598633 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 338: Validation loss: 0.46303534507751465 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 339: Validation loss: 0.4630395770072937 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 340: Validation loss: 0.4630450904369354 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 341: Validation loss: 0.4630517363548279 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 342: Validation loss: 0.46305957436561584 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 343: Validation loss: 0.4630686044692993 Best loss: 0.46302980184555054 Accuracy: 0.8466666340827942 \n",
      "Epoch 344: Validation loss: 0.46307870745658875 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 345: Validation loss: 0.4630899727344513 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 346: Validation loss: 0.4631023705005646 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 347: Validation loss: 0.4631158411502838 Best loss: 0.46302980184555054 Accuracy: 0.8466666340827942 \n",
      "Epoch 348: Validation loss: 0.46313050389289856 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 349: Validation loss: 0.4631461203098297 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 350: Validation loss: 0.46316295862197876 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 351: Validation loss: 0.4631807208061218 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 352: Validation loss: 0.4631996750831604 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 353: Validation loss: 0.46321961283683777 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 354: Validation loss: 0.4632405638694763 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Total training time: 893.5655002593994\n",
      "INFO:tensorflow:Restoring parameters from ./Team20_HW3.ckpt\n",
      "Test accuracy:  0.821642\n"
     ]
    }
   ],
   "source": [
    "# some hyperparams\n",
    "batch_size = 128\n",
    "# An epoch means one iteration over all of the training data\n",
    "train_steps = round(len(X_train2) / batch_size)\n",
    "\n",
    "training_epochs = 1000\n",
    "# If validation loss does not improve after certain steps of training, apply early stopping\n",
    "early_stopping_epoch = 20\n",
    "\n",
    "# Early stopping variables\n",
    "best_loss = 10000000\n",
    "best_epoch = 0\n",
    "early_stopped = False\n",
    "\n",
    "# Prepare our training dataset with batch\n",
    "dataset_batch = tf.contrib.data.Dataset.from_tensor_slices((X_train2, y_train2)).batch(batch_size).repeat(training_epochs)\n",
    "dataset_batch = dataset_batch.make_initializable_iterator()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize\n",
    "    sess.run(init_g)\n",
    "    sess.run(dataset_batch.initializer)\n",
    "    \n",
    "    # restore our model\n",
    "    restore_saver.restore(sess, \"./hw2_model/Team20_HW2.ckpt\")\n",
    "    for var in output_layer:\n",
    "        var.initializer.run()\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training 1000 epochs\n",
    "    for epoch in range(0, training_epochs):\n",
    "        # Training steps\n",
    "        for i in range(train_steps):\n",
    "            X_in, y_in = sess.run(dataset_batch.get_next())\n",
    "            sess.run(training_op, feed_dict={x: X_in, y: y_in, training_mode: False})\n",
    "\n",
    "        # Validate accuracy every epoch\n",
    "        curr_loss, curr_accuracy = sess.run([loss, accuracy], feed_dict={x: X_valid2, y: y_valid2, training_mode: False})\n",
    "        \n",
    "        # Save checkpoint of current model if it performs better\n",
    "        if best_loss > curr_loss:\n",
    "            best_loss = curr_loss\n",
    "            save_path = saver.save(sess, \"./Team20_HW3.ckpt\")\n",
    "            best_epoch = epoch        \n",
    "        # Early stop if model does not improve for certain epoch\n",
    "        elif epoch - best_epoch >= early_stopping_epoch:\n",
    "            early_stopped = True\n",
    "            break\n",
    "        \n",
    "        print(\"Epoch {}: Validation loss: {} Best loss: {} Accuracy: {} \".format(epoch, curr_loss, best_loss ,curr_accuracy))\n",
    "\n",
    "    # Save checkpoint in case the training is not early-stopped\n",
    "    if not early_stopped:\n",
    "        print(\"save best model\")\n",
    "        save_path = saver.save(sess, \"./Team20_HW3.ckpt\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Total training time: \" + str(end_time - start_time))    \n",
    "    \n",
    "    # Get the best model\n",
    "    saver.restore(sess, \"./Team20_HW3.ckpt\")\n",
    "    \n",
    "    # Total accuracy\n",
    "    final_accuracy = sess.run(accuracy, feed_dict={x: X_test2, y: y_test2, training_mode: False})\n",
    "    print(\"Test accuracy: \", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3.2 Cache 5th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense4/Elu:0\", shape=(?, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Step 3.5\n",
    "# Retrive the output of fifth layer, see tensorboard to know the output of fifth layer tensor is dense4/Elu.\n",
    "fifth_dense_output = tf.get_default_graph().get_tensor_by_name(\"dense4/Elu:0\")\n",
    "print(fifth_dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./hw2_model/Team20_HW2.ckpt\n",
      "Epoch 0: Validation loss: 4.056200981140137 Best loss: 4.056200981140137 Accuracy: 0.2666666507720947 \n",
      "Epoch 1: Validation loss: 3.7506086826324463 Best loss: 3.7506086826324463 Accuracy: 0.273333340883255 \n",
      "Epoch 2: Validation loss: 3.4611799716949463 Best loss: 3.4611799716949463 Accuracy: 0.2933333218097687 \n",
      "Epoch 3: Validation loss: 3.1907920837402344 Best loss: 3.1907920837402344 Accuracy: 0.30666667222976685 \n",
      "Epoch 4: Validation loss: 2.940844774246216 Best loss: 2.940844774246216 Accuracy: 0.3333333134651184 \n",
      "Epoch 5: Validation loss: 2.71216082572937 Best loss: 2.71216082572937 Accuracy: 0.3399999737739563 \n",
      "Epoch 6: Validation loss: 2.5051674842834473 Best loss: 2.5051674842834473 Accuracy: 0.36666664481163025 \n",
      "Epoch 7: Validation loss: 2.319786787033081 Best loss: 2.319786787033081 Accuracy: 0.4266666769981384 \n",
      "Epoch 8: Validation loss: 2.1552441120147705 Best loss: 2.1552441120147705 Accuracy: 0.4399999976158142 \n",
      "Epoch 9: Validation loss: 2.0100224018096924 Best loss: 2.0100224018096924 Accuracy: 0.4599999785423279 \n",
      "Epoch 10: Validation loss: 1.882073998451233 Best loss: 1.882073998451233 Accuracy: 0.48000001907348633 \n",
      "Epoch 11: Validation loss: 1.7691736221313477 Best loss: 1.7691736221313477 Accuracy: 0.5 \n",
      "Epoch 12: Validation loss: 1.6692354679107666 Best loss: 1.6692354679107666 Accuracy: 0.5133333206176758 \n",
      "Epoch 13: Validation loss: 1.5804729461669922 Best loss: 1.5804729461669922 Accuracy: 0.5133333206176758 \n",
      "Epoch 14: Validation loss: 1.501415491104126 Best loss: 1.501415491104126 Accuracy: 0.5266666412353516 \n",
      "Epoch 15: Validation loss: 1.4308536052703857 Best loss: 1.4308536052703857 Accuracy: 0.5266666412353516 \n",
      "Epoch 16: Validation loss: 1.3677737712860107 Best loss: 1.3677737712860107 Accuracy: 0.5666666626930237 \n",
      "Epoch 17: Validation loss: 1.311307668685913 Best loss: 1.311307668685913 Accuracy: 0.5866666436195374 \n",
      "Epoch 18: Validation loss: 1.260694146156311 Best loss: 1.260694146156311 Accuracy: 0.6200000047683716 \n",
      "Epoch 19: Validation loss: 1.2152531147003174 Best loss: 1.2152531147003174 Accuracy: 0.6266666650772095 \n",
      "Epoch 20: Validation loss: 1.1743674278259277 Best loss: 1.1743674278259277 Accuracy: 0.6266666650772095 \n",
      "Epoch 21: Validation loss: 1.1374754905700684 Best loss: 1.1374754905700684 Accuracy: 0.6399999856948853 \n",
      "Epoch 22: Validation loss: 1.104069709777832 Best loss: 1.104069709777832 Accuracy: 0.6466666460037231 \n",
      "Epoch 23: Validation loss: 1.0736979246139526 Best loss: 1.0736979246139526 Accuracy: 0.6399999856948853 \n",
      "Epoch 24: Validation loss: 1.0459692478179932 Best loss: 1.0459692478179932 Accuracy: 0.6466666460037231 \n",
      "Epoch 25: Validation loss: 1.0205498933792114 Best loss: 1.0205498933792114 Accuracy: 0.653333306312561 \n",
      "Epoch 26: Validation loss: 0.9971588253974915 Best loss: 0.9971588253974915 Accuracy: 0.6599999666213989 \n",
      "Epoch 27: Validation loss: 0.9755600690841675 Best loss: 0.9755600690841675 Accuracy: 0.6866666674613953 \n",
      "Epoch 28: Validation loss: 0.9555548429489136 Best loss: 0.9555548429489136 Accuracy: 0.6933333873748779 \n",
      "Epoch 29: Validation loss: 0.9369736909866333 Best loss: 0.9369736909866333 Accuracy: 0.6933333277702332 \n",
      "Epoch 30: Validation loss: 0.9196711778640747 Best loss: 0.9196711778640747 Accuracy: 0.6866666674613953 \n",
      "Epoch 31: Validation loss: 0.9035205245018005 Best loss: 0.9035205245018005 Accuracy: 0.6799999475479126 \n",
      "Epoch 32: Validation loss: 0.888410747051239 Best loss: 0.888410747051239 Accuracy: 0.6933333277702332 \n",
      "Epoch 33: Validation loss: 0.874243974685669 Best loss: 0.874243974685669 Accuracy: 0.699999988079071 \n",
      "Epoch 34: Validation loss: 0.8609328866004944 Best loss: 0.8609328866004944 Accuracy: 0.699999988079071 \n",
      "Epoch 35: Validation loss: 0.848399817943573 Best loss: 0.848399817943573 Accuracy: 0.7066667079925537 \n",
      "Epoch 36: Validation loss: 0.836575448513031 Best loss: 0.836575448513031 Accuracy: 0.7066667079925537 \n",
      "Epoch 37: Validation loss: 0.8253979682922363 Best loss: 0.8253979682922363 Accuracy: 0.7200000286102295 \n",
      "Epoch 38: Validation loss: 0.8148122429847717 Best loss: 0.8148122429847717 Accuracy: 0.7266666889190674 \n",
      "Epoch 39: Validation loss: 0.8047690391540527 Best loss: 0.8047690391540527 Accuracy: 0.7266666889190674 \n",
      "Epoch 40: Validation loss: 0.795224666595459 Best loss: 0.795224666595459 Accuracy: 0.7333333492279053 \n",
      "Epoch 41: Validation loss: 0.7861401438713074 Best loss: 0.7861401438713074 Accuracy: 0.7333333492279053 \n",
      "Epoch 42: Validation loss: 0.7774810194969177 Best loss: 0.7774810194969177 Accuracy: 0.746666669845581 \n",
      "Epoch 43: Validation loss: 0.7692162394523621 Best loss: 0.7692162394523621 Accuracy: 0.746666669845581 \n",
      "Epoch 44: Validation loss: 0.7613182663917542 Best loss: 0.7613182663917542 Accuracy: 0.746666669845581 \n",
      "Epoch 45: Validation loss: 0.753762423992157 Best loss: 0.753762423992157 Accuracy: 0.753333330154419 \n",
      "Epoch 46: Validation loss: 0.7465263605117798 Best loss: 0.7465263605117798 Accuracy: 0.753333330154419 \n",
      "Epoch 47: Validation loss: 0.739590048789978 Best loss: 0.739590048789978 Accuracy: 0.7599999904632568 \n",
      "Epoch 48: Validation loss: 0.7329350113868713 Best loss: 0.7329350113868713 Accuracy: 0.7599999904632568 \n",
      "Epoch 49: Validation loss: 0.7265447378158569 Best loss: 0.7265447378158569 Accuracy: 0.7666666507720947 \n",
      "Epoch 50: Validation loss: 0.7204034328460693 Best loss: 0.7204034328460693 Accuracy: 0.7666666507720947 \n",
      "Epoch 51: Validation loss: 0.7144972085952759 Best loss: 0.7144972085952759 Accuracy: 0.7666666507720947 \n",
      "Epoch 52: Validation loss: 0.7088125348091125 Best loss: 0.7088125348091125 Accuracy: 0.7666666507720947 \n",
      "Epoch 53: Validation loss: 0.7033374309539795 Best loss: 0.7033374309539795 Accuracy: 0.7666666507720947 \n",
      "Epoch 54: Validation loss: 0.698060154914856 Best loss: 0.698060154914856 Accuracy: 0.7666666507720947 \n",
      "Epoch 55: Validation loss: 0.6929702162742615 Best loss: 0.6929702162742615 Accuracy: 0.7666666507720947 \n",
      "Epoch 56: Validation loss: 0.6880577802658081 Best loss: 0.6880577802658081 Accuracy: 0.7666666507720947 \n",
      "Epoch 57: Validation loss: 0.6833131909370422 Best loss: 0.6833131909370422 Accuracy: 0.7733333110809326 \n",
      "Epoch 58: Validation loss: 0.678727924823761 Best loss: 0.678727924823761 Accuracy: 0.7733333110809326 \n",
      "Epoch 59: Validation loss: 0.6742936372756958 Best loss: 0.6742936372756958 Accuracy: 0.7733333110809326 \n",
      "Epoch 60: Validation loss: 0.6700029373168945 Best loss: 0.6700029373168945 Accuracy: 0.7733333110809326 \n",
      "Epoch 61: Validation loss: 0.665848433971405 Best loss: 0.665848433971405 Accuracy: 0.7733333110809326 \n",
      "Epoch 62: Validation loss: 0.6618235111236572 Best loss: 0.6618235111236572 Accuracy: 0.7733333110809326 \n",
      "Epoch 63: Validation loss: 0.6579217314720154 Best loss: 0.6579217314720154 Accuracy: 0.7733333110809326 \n",
      "Epoch 64: Validation loss: 0.6541371941566467 Best loss: 0.6541371941566467 Accuracy: 0.7866666316986084 \n",
      "Epoch 65: Validation loss: 0.6504644155502319 Best loss: 0.6504644155502319 Accuracy: 0.7866666316986084 \n",
      "Epoch 66: Validation loss: 0.6468981504440308 Best loss: 0.6468981504440308 Accuracy: 0.7866666316986084 \n",
      "Epoch 67: Validation loss: 0.6434333324432373 Best loss: 0.6434333324432373 Accuracy: 0.7866666316986084 \n",
      "Epoch 68: Validation loss: 0.6400654315948486 Best loss: 0.6400654315948486 Accuracy: 0.7866666316986084 \n",
      "Epoch 69: Validation loss: 0.636789858341217 Best loss: 0.636789858341217 Accuracy: 0.7866666316986084 \n",
      "Epoch 70: Validation loss: 0.6336029171943665 Best loss: 0.6336029171943665 Accuracy: 0.7933332920074463 \n",
      "Epoch 71: Validation loss: 0.6305002570152283 Best loss: 0.6305002570152283 Accuracy: 0.7933332920074463 \n",
      "Epoch 72: Validation loss: 0.6274784207344055 Best loss: 0.6274784207344055 Accuracy: 0.7933332920074463 \n",
      "Epoch 73: Validation loss: 0.624534010887146 Best loss: 0.624534010887146 Accuracy: 0.7933332920074463 \n",
      "Epoch 74: Validation loss: 0.6216636300086975 Best loss: 0.6216636300086975 Accuracy: 0.7933332920074463 \n",
      "Epoch 75: Validation loss: 0.618864119052887 Best loss: 0.618864119052887 Accuracy: 0.7933332920074463 \n",
      "Epoch 76: Validation loss: 0.6161326169967651 Best loss: 0.6161326169967651 Accuracy: 0.7933332920074463 \n",
      "Epoch 77: Validation loss: 0.6134665608406067 Best loss: 0.6134665608406067 Accuracy: 0.7933332920074463 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Validation loss: 0.6108630299568176 Best loss: 0.6108630299568176 Accuracy: 0.7999999523162842 \n",
      "Epoch 79: Validation loss: 0.6083198189735413 Best loss: 0.6083198189735413 Accuracy: 0.7999999523162842 \n",
      "Epoch 80: Validation loss: 0.6058343648910522 Best loss: 0.6058343648910522 Accuracy: 0.8066666722297668 \n",
      "Epoch 81: Validation loss: 0.6034047603607178 Best loss: 0.6034047603607178 Accuracy: 0.8066666126251221 \n",
      "Epoch 82: Validation loss: 0.6010286211967468 Best loss: 0.6010286211967468 Accuracy: 0.8199999928474426 \n",
      "Epoch 83: Validation loss: 0.5987041592597961 Best loss: 0.5987041592597961 Accuracy: 0.8199999928474426 \n",
      "Epoch 84: Validation loss: 0.5964294672012329 Best loss: 0.5964294672012329 Accuracy: 0.8199999928474426 \n",
      "Epoch 85: Validation loss: 0.5942028760910034 Best loss: 0.5942028760910034 Accuracy: 0.8199999928474426 \n",
      "Epoch 86: Validation loss: 0.5920226573944092 Best loss: 0.5920226573944092 Accuracy: 0.8199999928474426 \n",
      "Epoch 87: Validation loss: 0.5898870229721069 Best loss: 0.5898870229721069 Accuracy: 0.8199999928474426 \n",
      "Epoch 88: Validation loss: 0.587794840335846 Best loss: 0.587794840335846 Accuracy: 0.8199999928474426 \n",
      "Epoch 89: Validation loss: 0.5857445001602173 Best loss: 0.5857445001602173 Accuracy: 0.8199999928474426 \n",
      "Epoch 90: Validation loss: 0.5837346911430359 Best loss: 0.5837346911430359 Accuracy: 0.8199999928474426 \n",
      "Epoch 91: Validation loss: 0.581764280796051 Best loss: 0.581764280796051 Accuracy: 0.8199999928474426 \n",
      "Epoch 92: Validation loss: 0.5798318982124329 Best loss: 0.5798318982124329 Accuracy: 0.8199999928474426 \n",
      "Epoch 93: Validation loss: 0.5779364705085754 Best loss: 0.5779364705085754 Accuracy: 0.8199999928474426 \n",
      "Epoch 94: Validation loss: 0.576076865196228 Best loss: 0.576076865196228 Accuracy: 0.8199999928474426 \n",
      "Epoch 95: Validation loss: 0.5742521286010742 Best loss: 0.5742521286010742 Accuracy: 0.8199999928474426 \n",
      "Epoch 96: Validation loss: 0.5724612474441528 Best loss: 0.5724612474441528 Accuracy: 0.8199999928474426 \n",
      "Epoch 97: Validation loss: 0.5707032680511475 Best loss: 0.5707032680511475 Accuracy: 0.8199999928474426 \n",
      "Epoch 98: Validation loss: 0.5689772367477417 Best loss: 0.5689772367477417 Accuracy: 0.8199999928474426 \n",
      "Epoch 99: Validation loss: 0.5672824382781982 Best loss: 0.5672824382781982 Accuracy: 0.8199999928474426 \n",
      "Epoch 100: Validation loss: 0.5656180381774902 Best loss: 0.5656180381774902 Accuracy: 0.8199999928474426 \n",
      "Epoch 101: Validation loss: 0.5639832019805908 Best loss: 0.5639832019805908 Accuracy: 0.8199999928474426 \n",
      "Epoch 102: Validation loss: 0.5623772144317627 Best loss: 0.5623772144317627 Accuracy: 0.8199999928474426 \n",
      "Epoch 103: Validation loss: 0.5607993602752686 Best loss: 0.5607993602752686 Accuracy: 0.8199999928474426 \n",
      "Epoch 104: Validation loss: 0.5592488646507263 Best loss: 0.5592488646507263 Accuracy: 0.8199999928474426 \n",
      "Epoch 105: Validation loss: 0.5577251315116882 Best loss: 0.5577251315116882 Accuracy: 0.8199999928474426 \n",
      "Epoch 106: Validation loss: 0.5562276244163513 Best loss: 0.5562276244163513 Accuracy: 0.8199999928474426 \n",
      "Epoch 107: Validation loss: 0.5547555088996887 Best loss: 0.5547555088996887 Accuracy: 0.8199999928474426 \n",
      "Epoch 108: Validation loss: 0.553308367729187 Best loss: 0.553308367729187 Accuracy: 0.8199999928474426 \n",
      "Epoch 109: Validation loss: 0.5518856644630432 Best loss: 0.5518856644630432 Accuracy: 0.8199999928474426 \n",
      "Epoch 110: Validation loss: 0.55048668384552 Best loss: 0.55048668384552 Accuracy: 0.8199999928474426 \n",
      "Epoch 111: Validation loss: 0.549111008644104 Best loss: 0.549111008644104 Accuracy: 0.8199999928474426 \n",
      "Epoch 112: Validation loss: 0.5477580428123474 Best loss: 0.5477580428123474 Accuracy: 0.8199999928474426 \n",
      "Epoch 113: Validation loss: 0.5464273691177368 Best loss: 0.5464273691177368 Accuracy: 0.8199999928474426 \n",
      "Epoch 114: Validation loss: 0.5451184511184692 Best loss: 0.5451184511184692 Accuracy: 0.8199999928474426 \n",
      "Epoch 115: Validation loss: 0.5438308715820312 Best loss: 0.5438308715820312 Accuracy: 0.8199999928474426 \n",
      "Epoch 116: Validation loss: 0.5425640940666199 Best loss: 0.5425640940666199 Accuracy: 0.8199999928474426 \n",
      "Epoch 117: Validation loss: 0.5413176417350769 Best loss: 0.5413176417350769 Accuracy: 0.8199999928474426 \n",
      "Epoch 118: Validation loss: 0.5400912761688232 Best loss: 0.5400912761688232 Accuracy: 0.8266666531562805 \n",
      "Epoch 119: Validation loss: 0.5388844013214111 Best loss: 0.5388844013214111 Accuracy: 0.8333333134651184 \n",
      "Epoch 120: Validation loss: 0.5376967191696167 Best loss: 0.5376967191696167 Accuracy: 0.8333333134651184 \n",
      "Epoch 121: Validation loss: 0.5365277528762817 Best loss: 0.5365277528762817 Accuracy: 0.8333333134651184 \n",
      "Epoch 122: Validation loss: 0.5353771448135376 Best loss: 0.5353771448135376 Accuracy: 0.8333333134651184 \n",
      "Epoch 123: Validation loss: 0.5342444777488708 Best loss: 0.5342444777488708 Accuracy: 0.8333333134651184 \n",
      "Epoch 124: Validation loss: 0.5331295728683472 Best loss: 0.5331295728683472 Accuracy: 0.8333333134651184 \n",
      "Epoch 125: Validation loss: 0.5320318341255188 Best loss: 0.5320318341255188 Accuracy: 0.8333333134651184 \n",
      "Epoch 126: Validation loss: 0.5309511423110962 Best loss: 0.5309511423110962 Accuracy: 0.8333333134651184 \n",
      "Epoch 127: Validation loss: 0.5298870205879211 Best loss: 0.5298870205879211 Accuracy: 0.8333333134651184 \n",
      "Epoch 128: Validation loss: 0.528839111328125 Best loss: 0.528839111328125 Accuracy: 0.8333333134651184 \n",
      "Epoch 129: Validation loss: 0.5278071165084839 Best loss: 0.5278071165084839 Accuracy: 0.8333333134651184 \n",
      "Epoch 130: Validation loss: 0.5267909169197083 Best loss: 0.5267909169197083 Accuracy: 0.8333333134651184 \n",
      "Epoch 131: Validation loss: 0.5257899761199951 Best loss: 0.5257899761199951 Accuracy: 0.8333333134651184 \n",
      "Epoch 132: Validation loss: 0.5248041152954102 Best loss: 0.5248041152954102 Accuracy: 0.8333333134651184 \n",
      "Epoch 133: Validation loss: 0.5238330364227295 Best loss: 0.5238330364227295 Accuracy: 0.8333333134651184 \n",
      "Epoch 134: Validation loss: 0.5228764414787292 Best loss: 0.5228764414787292 Accuracy: 0.8333333134651184 \n",
      "Epoch 135: Validation loss: 0.5219340920448303 Best loss: 0.5219340920448303 Accuracy: 0.8333333134651184 \n",
      "Epoch 136: Validation loss: 0.5210056304931641 Best loss: 0.5210056304931641 Accuracy: 0.8399999737739563 \n",
      "Epoch 137: Validation loss: 0.5200909972190857 Best loss: 0.5200909972190857 Accuracy: 0.8400000333786011 \n",
      "Epoch 138: Validation loss: 0.5191897749900818 Best loss: 0.5191897749900818 Accuracy: 0.8399999737739563 \n",
      "Epoch 139: Validation loss: 0.5183017253875732 Best loss: 0.5183017253875732 Accuracy: 0.8399999737739563 \n",
      "Epoch 140: Validation loss: 0.5174267292022705 Best loss: 0.5174267292022705 Accuracy: 0.846666693687439 \n",
      "Epoch 141: Validation loss: 0.5165644288063049 Best loss: 0.5165644288063049 Accuracy: 0.846666693687439 \n",
      "Epoch 142: Validation loss: 0.515714704990387 Best loss: 0.515714704990387 Accuracy: 0.846666693687439 \n",
      "Epoch 143: Validation loss: 0.5148772597312927 Best loss: 0.5148772597312927 Accuracy: 0.846666693687439 \n",
      "Epoch 144: Validation loss: 0.5140519142150879 Best loss: 0.5140519142150879 Accuracy: 0.8466666340827942 \n",
      "Epoch 145: Validation loss: 0.5132384300231934 Best loss: 0.5132384300231934 Accuracy: 0.846666693687439 \n",
      "Epoch 146: Validation loss: 0.5124367475509644 Best loss: 0.5124367475509644 Accuracy: 0.846666693687439 \n",
      "Epoch 147: Validation loss: 0.5116463899612427 Best loss: 0.5116463899612427 Accuracy: 0.846666693687439 \n",
      "Epoch 148: Validation loss: 0.5108673572540283 Best loss: 0.5108673572540283 Accuracy: 0.8466666340827942 \n",
      "Epoch 149: Validation loss: 0.5100994110107422 Best loss: 0.5100994110107422 Accuracy: 0.846666693687439 \n",
      "Epoch 150: Validation loss: 0.5093424916267395 Best loss: 0.5093424916267395 Accuracy: 0.8466666340827942 \n",
      "Epoch 151: Validation loss: 0.5085961818695068 Best loss: 0.5085961818695068 Accuracy: 0.846666693687439 \n",
      "Epoch 152: Validation loss: 0.507860541343689 Best loss: 0.507860541343689 Accuracy: 0.8466666340827942 \n",
      "Epoch 153: Validation loss: 0.507135272026062 Best loss: 0.507135272026062 Accuracy: 0.846666693687439 \n",
      "Epoch 154: Validation loss: 0.5064201951026917 Best loss: 0.5064201951026917 Accuracy: 0.846666693687439 \n",
      "Epoch 155: Validation loss: 0.5057151913642883 Best loss: 0.5057151913642883 Accuracy: 0.8466666340827942 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156: Validation loss: 0.5050200819969177 Best loss: 0.5050200819969177 Accuracy: 0.846666693687439 \n",
      "Epoch 157: Validation loss: 0.5043348073959351 Best loss: 0.5043348073959351 Accuracy: 0.846666693687439 \n",
      "Epoch 158: Validation loss: 0.5036590695381165 Best loss: 0.5036590695381165 Accuracy: 0.846666693687439 \n",
      "Epoch 159: Validation loss: 0.5029927492141724 Best loss: 0.5029927492141724 Accuracy: 0.8466666340827942 \n",
      "Epoch 160: Validation loss: 0.5023357272148132 Best loss: 0.5023357272148132 Accuracy: 0.846666693687439 \n",
      "Epoch 161: Validation loss: 0.5016879439353943 Best loss: 0.5016879439353943 Accuracy: 0.8466666340827942 \n",
      "Epoch 162: Validation loss: 0.5010491609573364 Best loss: 0.5010491609573364 Accuracy: 0.846666693687439 \n",
      "Epoch 163: Validation loss: 0.5004191994667053 Best loss: 0.5004191994667053 Accuracy: 0.8466666340827942 \n",
      "Epoch 164: Validation loss: 0.499798059463501 Best loss: 0.499798059463501 Accuracy: 0.846666693687439 \n",
      "Epoch 165: Validation loss: 0.4991855025291443 Best loss: 0.4991855025291443 Accuracy: 0.846666693687439 \n",
      "Epoch 166: Validation loss: 0.4985814094543457 Best loss: 0.4985814094543457 Accuracy: 0.846666693687439 \n",
      "Epoch 167: Validation loss: 0.49798583984375 Best loss: 0.49798583984375 Accuracy: 0.846666693687439 \n",
      "Epoch 168: Validation loss: 0.49739840626716614 Best loss: 0.49739840626716614 Accuracy: 0.8466666340827942 \n",
      "Epoch 169: Validation loss: 0.4968191385269165 Best loss: 0.4968191385269165 Accuracy: 0.846666693687439 \n",
      "Epoch 170: Validation loss: 0.49624791741371155 Best loss: 0.49624791741371155 Accuracy: 0.846666693687439 \n",
      "Epoch 171: Validation loss: 0.49568450450897217 Best loss: 0.49568450450897217 Accuracy: 0.8466666340827942 \n",
      "Epoch 172: Validation loss: 0.4951289892196655 Best loss: 0.4951289892196655 Accuracy: 0.8533332943916321 \n",
      "Epoch 173: Validation loss: 0.4945811629295349 Best loss: 0.4945811629295349 Accuracy: 0.8533332943916321 \n",
      "Epoch 174: Validation loss: 0.49404090642929077 Best loss: 0.49404090642929077 Accuracy: 0.8533333539962769 \n",
      "Epoch 175: Validation loss: 0.4935080111026764 Best loss: 0.4935080111026764 Accuracy: 0.8533332943916321 \n",
      "Epoch 176: Validation loss: 0.49298256635665894 Best loss: 0.49298256635665894 Accuracy: 0.8533333539962769 \n",
      "Epoch 177: Validation loss: 0.4924643635749817 Best loss: 0.4924643635749817 Accuracy: 0.8533333539962769 \n",
      "Epoch 178: Validation loss: 0.4919533133506775 Best loss: 0.4919533133506775 Accuracy: 0.8533333539962769 \n",
      "Epoch 179: Validation loss: 0.4914493262767792 Best loss: 0.4914493262767792 Accuracy: 0.8533333539962769 \n",
      "Epoch 180: Validation loss: 0.49095240235328674 Best loss: 0.49095240235328674 Accuracy: 0.8533333539962769 \n",
      "Epoch 181: Validation loss: 0.4904623031616211 Best loss: 0.4904623031616211 Accuracy: 0.8533333539962769 \n",
      "Epoch 182: Validation loss: 0.48997896909713745 Best loss: 0.48997896909713745 Accuracy: 0.8533332943916321 \n",
      "Epoch 183: Validation loss: 0.48950234055519104 Best loss: 0.48950234055519104 Accuracy: 0.8533333539962769 \n",
      "Epoch 184: Validation loss: 0.4890323877334595 Best loss: 0.4890323877334595 Accuracy: 0.8533332943916321 \n",
      "Epoch 185: Validation loss: 0.48856890201568604 Best loss: 0.48856890201568604 Accuracy: 0.8533333539962769 \n",
      "Epoch 186: Validation loss: 0.48811185359954834 Best loss: 0.48811185359954834 Accuracy: 0.8533332943916321 \n",
      "Epoch 187: Validation loss: 0.4876611530780792 Best loss: 0.4876611530780792 Accuracy: 0.8533333539962769 \n",
      "Epoch 188: Validation loss: 0.4872167706489563 Best loss: 0.4872167706489563 Accuracy: 0.8533332943916321 \n",
      "Epoch 189: Validation loss: 0.4867785573005676 Best loss: 0.4867785573005676 Accuracy: 0.8533333539962769 \n",
      "Epoch 190: Validation loss: 0.48634645342826843 Best loss: 0.48634645342826843 Accuracy: 0.8533333539962769 \n",
      "Epoch 191: Validation loss: 0.48592036962509155 Best loss: 0.48592036962509155 Accuracy: 0.8533332943916321 \n",
      "Epoch 192: Validation loss: 0.4855002164840698 Best loss: 0.4855002164840698 Accuracy: 0.8533332943916321 \n",
      "Epoch 193: Validation loss: 0.48508596420288086 Best loss: 0.48508596420288086 Accuracy: 0.8533333539962769 \n",
      "Epoch 194: Validation loss: 0.4846775531768799 Best loss: 0.4846775531768799 Accuracy: 0.8533333539962769 \n",
      "Epoch 195: Validation loss: 0.48427480459213257 Best loss: 0.48427480459213257 Accuracy: 0.8533333539962769 \n",
      "Epoch 196: Validation loss: 0.4838778078556061 Best loss: 0.4838778078556061 Accuracy: 0.8533333539962769 \n",
      "Epoch 197: Validation loss: 0.4834863543510437 Best loss: 0.4834863543510437 Accuracy: 0.8533333539962769 \n",
      "Epoch 198: Validation loss: 0.48310044407844543 Best loss: 0.48310044407844543 Accuracy: 0.8533332943916321 \n",
      "Epoch 199: Validation loss: 0.4827199876308441 Best loss: 0.4827199876308441 Accuracy: 0.8533333539962769 \n",
      "Epoch 200: Validation loss: 0.4823448956012726 Best loss: 0.4823448956012726 Accuracy: 0.8533333539962769 \n",
      "Epoch 201: Validation loss: 0.48197516798973083 Best loss: 0.48197516798973083 Accuracy: 0.8533332943916321 \n",
      "Epoch 202: Validation loss: 0.48161062598228455 Best loss: 0.48161062598228455 Accuracy: 0.8533332943916321 \n",
      "Epoch 203: Validation loss: 0.4812512993812561 Best loss: 0.4812512993812561 Accuracy: 0.8533333539962769 \n",
      "Epoch 204: Validation loss: 0.48089709877967834 Best loss: 0.48089709877967834 Accuracy: 0.8533333539962769 \n",
      "Epoch 205: Validation loss: 0.48054802417755127 Best loss: 0.48054802417755127 Accuracy: 0.8466666340827942 \n",
      "Epoch 206: Validation loss: 0.48020392656326294 Best loss: 0.48020392656326294 Accuracy: 0.8466666340827942 \n",
      "Epoch 207: Validation loss: 0.4798647463321686 Best loss: 0.4798647463321686 Accuracy: 0.8466666340827942 \n",
      "Epoch 208: Validation loss: 0.4795305132865906 Best loss: 0.4795305132865906 Accuracy: 0.8466666340827942 \n",
      "Epoch 209: Validation loss: 0.479201078414917 Best loss: 0.479201078414917 Accuracy: 0.8466666340827942 \n",
      "Epoch 210: Validation loss: 0.47887635231018066 Best loss: 0.47887635231018066 Accuracy: 0.8466666340827942 \n",
      "Epoch 211: Validation loss: 0.47855642437934875 Best loss: 0.47855642437934875 Accuracy: 0.8466666340827942 \n",
      "Epoch 212: Validation loss: 0.4782412052154541 Best loss: 0.4782412052154541 Accuracy: 0.8466666340827942 \n",
      "Epoch 213: Validation loss: 0.4779304265975952 Best loss: 0.4779304265975952 Accuracy: 0.8466666340827942 \n",
      "Epoch 214: Validation loss: 0.4776242971420288 Best loss: 0.4776242971420288 Accuracy: 0.8466666340827942 \n",
      "Epoch 215: Validation loss: 0.47732260823249817 Best loss: 0.47732260823249817 Accuracy: 0.8466666340827942 \n",
      "Epoch 216: Validation loss: 0.47702544927597046 Best loss: 0.47702544927597046 Accuracy: 0.8466666340827942 \n",
      "Epoch 217: Validation loss: 0.4767325520515442 Best loss: 0.4767325520515442 Accuracy: 0.8466666340827942 \n",
      "Epoch 218: Validation loss: 0.4764441251754761 Best loss: 0.4764441251754761 Accuracy: 0.8466666340827942 \n",
      "Epoch 219: Validation loss: 0.4761599600315094 Best loss: 0.4761599600315094 Accuracy: 0.8466666340827942 \n",
      "Epoch 220: Validation loss: 0.475879967212677 Best loss: 0.475879967212677 Accuracy: 0.8466666340827942 \n",
      "Epoch 221: Validation loss: 0.4756042957305908 Best loss: 0.4756042957305908 Accuracy: 0.8466666340827942 \n",
      "Epoch 222: Validation loss: 0.47533273696899414 Best loss: 0.47533273696899414 Accuracy: 0.8466666340827942 \n",
      "Epoch 223: Validation loss: 0.47506529092788696 Best loss: 0.47506529092788696 Accuracy: 0.8466666340827942 \n",
      "Epoch 224: Validation loss: 0.4748018682003021 Best loss: 0.4748018682003021 Accuracy: 0.8466666340827942 \n",
      "Epoch 225: Validation loss: 0.47454243898391724 Best loss: 0.47454243898391724 Accuracy: 0.846666693687439 \n",
      "Epoch 226: Validation loss: 0.4742869734764099 Best loss: 0.4742869734764099 Accuracy: 0.8466666340827942 \n",
      "Epoch 227: Validation loss: 0.47403544187545776 Best loss: 0.47403544187545776 Accuracy: 0.8466666340827942 \n",
      "Epoch 228: Validation loss: 0.47378775477409363 Best loss: 0.47378775477409363 Accuracy: 0.8466666340827942 \n",
      "Epoch 229: Validation loss: 0.4735439419746399 Best loss: 0.4735439419746399 Accuracy: 0.8466666340827942 \n",
      "Epoch 230: Validation loss: 0.47330397367477417 Best loss: 0.47330397367477417 Accuracy: 0.8466666340827942 \n",
      "Epoch 231: Validation loss: 0.4730677306652069 Best loss: 0.4730677306652069 Accuracy: 0.8466666340827942 \n",
      "Epoch 232: Validation loss: 0.47283512353897095 Best loss: 0.47283512353897095 Accuracy: 0.8466666340827942 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233: Validation loss: 0.4726063013076782 Best loss: 0.4726063013076782 Accuracy: 0.8466666340827942 \n",
      "Epoch 234: Validation loss: 0.4723809063434601 Best loss: 0.4723809063434601 Accuracy: 0.8466666340827942 \n",
      "Epoch 235: Validation loss: 0.4721592664718628 Best loss: 0.4721592664718628 Accuracy: 0.8466666340827942 \n",
      "Epoch 236: Validation loss: 0.47194114327430725 Best loss: 0.47194114327430725 Accuracy: 0.8466666340827942 \n",
      "Epoch 237: Validation loss: 0.47172650694847107 Best loss: 0.47172650694847107 Accuracy: 0.8466666340827942 \n",
      "Epoch 238: Validation loss: 0.47151535749435425 Best loss: 0.47151535749435425 Accuracy: 0.8466666340827942 \n",
      "Epoch 239: Validation loss: 0.471307635307312 Best loss: 0.471307635307312 Accuracy: 0.8466666340827942 \n",
      "Epoch 240: Validation loss: 0.4711032509803772 Best loss: 0.4711032509803772 Accuracy: 0.8466666340827942 \n",
      "Epoch 241: Validation loss: 0.47090235352516174 Best loss: 0.47090235352516174 Accuracy: 0.8466666340827942 \n",
      "Epoch 242: Validation loss: 0.47070467472076416 Best loss: 0.47070467472076416 Accuracy: 0.8466666340827942 \n",
      "Epoch 243: Validation loss: 0.47051024436950684 Best loss: 0.47051024436950684 Accuracy: 0.8466666340827942 \n",
      "Epoch 244: Validation loss: 0.4703192412853241 Best loss: 0.4703192412853241 Accuracy: 0.8466666340827942 \n",
      "Epoch 245: Validation loss: 0.47013136744499207 Best loss: 0.47013136744499207 Accuracy: 0.8466666340827942 \n",
      "Epoch 246: Validation loss: 0.4699466824531555 Best loss: 0.4699466824531555 Accuracy: 0.8466666340827942 \n",
      "Epoch 247: Validation loss: 0.4697651267051697 Best loss: 0.4697651267051697 Accuracy: 0.846666693687439 \n",
      "Epoch 248: Validation loss: 0.4695867896080017 Best loss: 0.4695867896080017 Accuracy: 0.8466666340827942 \n",
      "Epoch 249: Validation loss: 0.4694114625453949 Best loss: 0.4694114625453949 Accuracy: 0.8466666340827942 \n",
      "Epoch 250: Validation loss: 0.46923914551734924 Best loss: 0.46923914551734924 Accuracy: 0.8466666340827942 \n",
      "Epoch 251: Validation loss: 0.46906986832618713 Best loss: 0.46906986832618713 Accuracy: 0.8466666340827942 \n",
      "Epoch 252: Validation loss: 0.4689036011695862 Best loss: 0.4689036011695862 Accuracy: 0.8466666340827942 \n",
      "Epoch 253: Validation loss: 0.468740314245224 Best loss: 0.468740314245224 Accuracy: 0.8466666340827942 \n",
      "Epoch 254: Validation loss: 0.46857988834381104 Best loss: 0.46857988834381104 Accuracy: 0.8466666340827942 \n",
      "Epoch 255: Validation loss: 0.4684223532676697 Best loss: 0.4684223532676697 Accuracy: 0.8466666340827942 \n",
      "Epoch 256: Validation loss: 0.4682677090167999 Best loss: 0.4682677090167999 Accuracy: 0.8466666340827942 \n",
      "Epoch 257: Validation loss: 0.4681159257888794 Best loss: 0.4681159257888794 Accuracy: 0.8466666340827942 \n",
      "Epoch 258: Validation loss: 0.4679669439792633 Best loss: 0.4679669439792633 Accuracy: 0.8466666340827942 \n",
      "Epoch 259: Validation loss: 0.4678207039833069 Best loss: 0.4678207039833069 Accuracy: 0.8466666340827942 \n",
      "Epoch 260: Validation loss: 0.4676772356033325 Best loss: 0.4676772356033325 Accuracy: 0.8466666340827942 \n",
      "Epoch 261: Validation loss: 0.46753644943237305 Best loss: 0.46753644943237305 Accuracy: 0.8466666340827942 \n",
      "Epoch 262: Validation loss: 0.46739843487739563 Best loss: 0.46739843487739563 Accuracy: 0.8466666340827942 \n",
      "Epoch 263: Validation loss: 0.46726304292678833 Best loss: 0.46726304292678833 Accuracy: 0.8466666340827942 \n",
      "Epoch 264: Validation loss: 0.46713027358055115 Best loss: 0.46713027358055115 Accuracy: 0.8466666340827942 \n",
      "Epoch 265: Validation loss: 0.46700021624565125 Best loss: 0.46700021624565125 Accuracy: 0.8466666340827942 \n",
      "Epoch 266: Validation loss: 0.46687257289886475 Best loss: 0.46687257289886475 Accuracy: 0.8466666340827942 \n",
      "Epoch 267: Validation loss: 0.46674761176109314 Best loss: 0.46674761176109314 Accuracy: 0.8466666340827942 \n",
      "Epoch 268: Validation loss: 0.4666251242160797 Best loss: 0.4666251242160797 Accuracy: 0.8466666340827942 \n",
      "Epoch 269: Validation loss: 0.46650514006614685 Best loss: 0.46650514006614685 Accuracy: 0.8466666340827942 \n",
      "Epoch 270: Validation loss: 0.4663877487182617 Best loss: 0.4663877487182617 Accuracy: 0.8466666340827942 \n",
      "Epoch 271: Validation loss: 0.4662726819515228 Best loss: 0.4662726819515228 Accuracy: 0.8399999737739563 \n",
      "Epoch 272: Validation loss: 0.4661600589752197 Best loss: 0.4661600589752197 Accuracy: 0.8399999737739563 \n",
      "Epoch 273: Validation loss: 0.4660499095916748 Best loss: 0.4660499095916748 Accuracy: 0.8399999737739563 \n",
      "Epoch 274: Validation loss: 0.4659420847892761 Best loss: 0.4659420847892761 Accuracy: 0.8399999737739563 \n",
      "Epoch 275: Validation loss: 0.46583661437034607 Best loss: 0.46583661437034607 Accuracy: 0.8399999737739563 \n",
      "Epoch 276: Validation loss: 0.46573343873023987 Best loss: 0.46573343873023987 Accuracy: 0.8399999737739563 \n",
      "Epoch 277: Validation loss: 0.4656326174736023 Best loss: 0.4656326174736023 Accuracy: 0.8399999737739563 \n",
      "Epoch 278: Validation loss: 0.4655340909957886 Best loss: 0.4655340909957886 Accuracy: 0.8399999737739563 \n",
      "Epoch 279: Validation loss: 0.46543774008750916 Best loss: 0.46543774008750916 Accuracy: 0.8399999737739563 \n",
      "Epoch 280: Validation loss: 0.4653436839580536 Best loss: 0.4653436839580536 Accuracy: 0.8399999737739563 \n",
      "Epoch 281: Validation loss: 0.4652519226074219 Best loss: 0.4652519226074219 Accuracy: 0.8399999737739563 \n",
      "Epoch 282: Validation loss: 0.4651622176170349 Best loss: 0.4651622176170349 Accuracy: 0.8399999737739563 \n",
      "Epoch 283: Validation loss: 0.465074747800827 Best loss: 0.465074747800827 Accuracy: 0.8399999737739563 \n",
      "Epoch 284: Validation loss: 0.4649895131587982 Best loss: 0.4649895131587982 Accuracy: 0.8399999737739563 \n",
      "Epoch 285: Validation loss: 0.4649061858654022 Best loss: 0.4649061858654022 Accuracy: 0.8399999737739563 \n",
      "Epoch 286: Validation loss: 0.46482518315315247 Best loss: 0.46482518315315247 Accuracy: 0.8399999737739563 \n",
      "Epoch 287: Validation loss: 0.4647461473941803 Best loss: 0.4647461473941803 Accuracy: 0.8399999737739563 \n",
      "Epoch 288: Validation loss: 0.4646691679954529 Best loss: 0.4646691679954529 Accuracy: 0.8399999737739563 \n",
      "Epoch 289: Validation loss: 0.4645942449569702 Best loss: 0.4645942449569702 Accuracy: 0.8399999737739563 \n",
      "Epoch 290: Validation loss: 0.4645213484764099 Best loss: 0.4645213484764099 Accuracy: 0.8399999737739563 \n",
      "Epoch 291: Validation loss: 0.46445053815841675 Best loss: 0.46445053815841675 Accuracy: 0.8399999737739563 \n",
      "Epoch 292: Validation loss: 0.46438151597976685 Best loss: 0.46438151597976685 Accuracy: 0.8399999737739563 \n",
      "Epoch 293: Validation loss: 0.4643145799636841 Best loss: 0.4643145799636841 Accuracy: 0.8399999737739563 \n",
      "Epoch 294: Validation loss: 0.46424949169158936 Best loss: 0.46424949169158936 Accuracy: 0.8399999737739563 \n",
      "Epoch 295: Validation loss: 0.46418648958206177 Best loss: 0.46418648958206177 Accuracy: 0.8399999737739563 \n",
      "Epoch 296: Validation loss: 0.46412527561187744 Best loss: 0.46412527561187744 Accuracy: 0.8399999737739563 \n",
      "Epoch 297: Validation loss: 0.4640659689903259 Best loss: 0.4640659689903259 Accuracy: 0.8399999737739563 \n",
      "Epoch 298: Validation loss: 0.46400851011276245 Best loss: 0.46400851011276245 Accuracy: 0.8399999737739563 \n",
      "Epoch 299: Validation loss: 0.4639528691768646 Best loss: 0.4639528691768646 Accuracy: 0.8399999737739563 \n",
      "Epoch 300: Validation loss: 0.4638991057872772 Best loss: 0.4638991057872772 Accuracy: 0.8399999737739563 \n",
      "Epoch 301: Validation loss: 0.46384716033935547 Best loss: 0.46384716033935547 Accuracy: 0.8399999737739563 \n",
      "Epoch 302: Validation loss: 0.4637968838214874 Best loss: 0.4637968838214874 Accuracy: 0.8399999737739563 \n",
      "Epoch 303: Validation loss: 0.46374842524528503 Best loss: 0.46374842524528503 Accuracy: 0.8399999737739563 \n",
      "Epoch 304: Validation loss: 0.4637017846107483 Best loss: 0.4637017846107483 Accuracy: 0.8399999737739563 \n",
      "Epoch 305: Validation loss: 0.46365678310394287 Best loss: 0.46365678310394287 Accuracy: 0.8399999737739563 \n",
      "Epoch 306: Validation loss: 0.4636135697364807 Best loss: 0.4636135697364807 Accuracy: 0.8399999737739563 \n",
      "Epoch 307: Validation loss: 0.4635719656944275 Best loss: 0.4635719656944275 Accuracy: 0.8399999737739563 \n",
      "Epoch 308: Validation loss: 0.46353206038475037 Best loss: 0.46353206038475037 Accuracy: 0.8399999737739563 \n",
      "Epoch 309: Validation loss: 0.46349388360977173 Best loss: 0.46349388360977173 Accuracy: 0.8399999737739563 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310: Validation loss: 0.46345722675323486 Best loss: 0.46345722675323486 Accuracy: 0.8399999737739563 \n",
      "Epoch 311: Validation loss: 0.4634222984313965 Best loss: 0.4634222984313965 Accuracy: 0.8399999737739563 \n",
      "Epoch 312: Validation loss: 0.46338897943496704 Best loss: 0.46338897943496704 Accuracy: 0.8399999737739563 \n",
      "Epoch 313: Validation loss: 0.46335726976394653 Best loss: 0.46335726976394653 Accuracy: 0.8399999737739563 \n",
      "Epoch 314: Validation loss: 0.4633270800113678 Best loss: 0.4633270800113678 Accuracy: 0.8399999737739563 \n",
      "Epoch 315: Validation loss: 0.4632984399795532 Best loss: 0.4632984399795532 Accuracy: 0.8399999737739563 \n",
      "Epoch 316: Validation loss: 0.4632713794708252 Best loss: 0.4632713794708252 Accuracy: 0.8399999737739563 \n",
      "Epoch 317: Validation loss: 0.46324580907821655 Best loss: 0.46324580907821655 Accuracy: 0.8399999737739563 \n",
      "Epoch 318: Validation loss: 0.46322187781333923 Best loss: 0.46322187781333923 Accuracy: 0.846666693687439 \n",
      "Epoch 319: Validation loss: 0.463199257850647 Best loss: 0.463199257850647 Accuracy: 0.8466666340827942 \n",
      "Epoch 320: Validation loss: 0.46317821741104126 Best loss: 0.46317821741104126 Accuracy: 0.846666693687439 \n",
      "Epoch 321: Validation loss: 0.46315863728523254 Best loss: 0.46315863728523254 Accuracy: 0.846666693687439 \n",
      "Epoch 322: Validation loss: 0.46314048767089844 Best loss: 0.46314048767089844 Accuracy: 0.8466666340827942 \n",
      "Epoch 323: Validation loss: 0.46312376856803894 Best loss: 0.46312376856803894 Accuracy: 0.846666693687439 \n",
      "Epoch 324: Validation loss: 0.46310850977897644 Best loss: 0.46310850977897644 Accuracy: 0.846666693687439 \n",
      "Epoch 325: Validation loss: 0.4630946218967438 Best loss: 0.4630946218967438 Accuracy: 0.8466666340827942 \n",
      "Epoch 326: Validation loss: 0.46308213472366333 Best loss: 0.46308213472366333 Accuracy: 0.8466666340827942 \n",
      "Epoch 327: Validation loss: 0.46307098865509033 Best loss: 0.46307098865509033 Accuracy: 0.846666693687439 \n",
      "Epoch 328: Validation loss: 0.46306121349334717 Best loss: 0.46306121349334717 Accuracy: 0.8466666340827942 \n",
      "Epoch 329: Validation loss: 0.4630528390407562 Best loss: 0.4630528390407562 Accuracy: 0.8466666340827942 \n",
      "Epoch 330: Validation loss: 0.46304574608802795 Best loss: 0.46304574608802795 Accuracy: 0.846666693687439 \n",
      "Epoch 331: Validation loss: 0.46303999423980713 Best loss: 0.46303999423980713 Accuracy: 0.846666693687439 \n",
      "Epoch 332: Validation loss: 0.4630354642868042 Best loss: 0.4630354642868042 Accuracy: 0.846666693687439 \n",
      "Epoch 333: Validation loss: 0.4630323350429535 Best loss: 0.4630323350429535 Accuracy: 0.846666693687439 \n",
      "Epoch 334: Validation loss: 0.4630304276943207 Best loss: 0.4630304276943207 Accuracy: 0.846666693687439 \n",
      "Epoch 335: Validation loss: 0.46302980184555054 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 336: Validation loss: 0.4630303382873535 Best loss: 0.46302980184555054 Accuracy: 0.8466666340827942 \n",
      "Epoch 337: Validation loss: 0.46303224563598633 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 338: Validation loss: 0.46303534507751465 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 339: Validation loss: 0.4630395770072937 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 340: Validation loss: 0.46304506063461304 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 341: Validation loss: 0.4630517363548279 Best loss: 0.46302980184555054 Accuracy: 0.8466666340827942 \n",
      "Epoch 342: Validation loss: 0.46305954456329346 Best loss: 0.46302980184555054 Accuracy: 0.8466666340827942 \n",
      "Epoch 343: Validation loss: 0.46306854486465454 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 344: Validation loss: 0.46307867765426636 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 345: Validation loss: 0.4630899727344513 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 346: Validation loss: 0.46310240030288696 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 347: Validation loss: 0.4631158411502838 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 348: Validation loss: 0.46313053369522095 Best loss: 0.46302980184555054 Accuracy: 0.8466666340827942 \n",
      "Epoch 349: Validation loss: 0.4631461501121521 Best loss: 0.46302980184555054 Accuracy: 0.8466666340827942 \n",
      "Epoch 350: Validation loss: 0.46316295862197876 Best loss: 0.46302980184555054 Accuracy: 0.8466666340827942 \n",
      "Epoch 351: Validation loss: 0.4631807208061218 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 352: Validation loss: 0.4631996750831604 Best loss: 0.46302980184555054 Accuracy: 0.8466666340827942 \n",
      "Epoch 353: Validation loss: 0.46321961283683777 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Epoch 354: Validation loss: 0.4632405936717987 Best loss: 0.46302980184555054 Accuracy: 0.846666693687439 \n",
      "Total training time: 773.5620684623718\n",
      "INFO:tensorflow:Restoring parameters from ./Team20_HW3_2_cache_5_layer.ckpt\n",
      "Test accuracy:  0.821642\n"
     ]
    }
   ],
   "source": [
    "# some hyperparams\n",
    "batch_size = 128\n",
    "# An epoch means one iteration over all of the training data\n",
    "train_steps = round(len(X_train2) / batch_size)\n",
    "\n",
    "training_epochs = 1000\n",
    "# If validation loss does not improve after certain steps of training, apply early stopping\n",
    "early_stopping_epoch = 20\n",
    "\n",
    "# Early stopping variables\n",
    "best_loss = 10000000\n",
    "best_epoch = 0\n",
    "early_stopped = False\n",
    "\n",
    "# Prepare our training dataset with batch\n",
    "dataset_batch = tf.contrib.data.Dataset.from_tensor_slices((X_train2, y_train2)).batch(batch_size).repeat(training_epochs)\n",
    "dataset_batch = dataset_batch.make_initializable_iterator()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize\n",
    "    sess.run(init_g)\n",
    "    sess.run(dataset_batch.initializer)\n",
    "    \n",
    "    # restore our model\n",
    "    restore_saver.restore(sess, \"./hw2_model/Team20_HW2.ckpt\")\n",
    "    for var in output_layer:\n",
    "        var.initializer.run()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Feed validation set into 5th layer and save the parms\n",
    "    dense5_output_valid = fifth_dense_output.eval(feed_dict={x: X_valid2, y: y_valid2, training_mode: False})\n",
    "    \n",
    "    # Training 1000 epochs\n",
    "    for epoch in range(0, training_epochs):\n",
    "        # Training steps\n",
    "        for i in range(1, train_steps+1):\n",
    "            X_in, y_in = sess.run(dataset_batch.get_next())\n",
    "            # Feed training set into 5th layer per batch and save the parms\n",
    "            dense5_output_train = fifth_dense_output.eval(feed_dict={x: X_in, y: y_in, training_mode: False})\n",
    "            # Directly feed the params of dense5 for training\n",
    "            sess.run(training_op, feed_dict={fifth_dense_output: dense5_output_train,  y: y_in, training_mode: False})\n",
    "\n",
    "        # Validate accuracy every epoch\n",
    "        curr_loss, curr_accuracy = sess.run([loss, accuracy], feed_dict={fifth_dense_output: dense5_output_valid, y: y_valid2, training_mode: False})\n",
    "        \n",
    "        # Save checkpoint of current model if it performs better\n",
    "        if best_loss > curr_loss:\n",
    "            best_loss = curr_loss\n",
    "            save_path = saver.save(sess, \"./Team20_HW3_2_cache_5_layer.ckpt\")\n",
    "            best_epoch = epoch        \n",
    "        # Early stop if model does not improve for certain epoch\n",
    "        elif epoch - best_epoch >= early_stopping_epoch:\n",
    "            early_stopped = True\n",
    "            break\n",
    "        \n",
    "        print(\"Epoch {}: Validation loss: {} Best loss: {} Accuracy: {} \".format(epoch, curr_loss, best_loss ,curr_accuracy))\n",
    "    \n",
    "    # Save checkpoint in case the training is not early-stopped\n",
    "    if not early_stopped:\n",
    "        print(\"save best model\")\n",
    "        save_path = saver.save(sess, \"./Team20_HW3_2_cache_5_layer.ckpt\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Total training time: \" + str(end_time - start_time))\n",
    "\n",
    "    # Get the best model\n",
    "    saver.restore(sess, \"./Team20_HW3_2_cache_5_layer.ckpt\")\n",
    "    \n",
    "    # Total accuracy\n",
    "    final_accuracy = sess.run(accuracy, feed_dict={x: X_test2, y: y_test2, training_mode: False})\n",
    "    print(\"Test accuracy: \", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The total training time of HW3.1 is 893.5655002593994.\n",
    "#### The total training time of HW3.2 is 773.5620684623718.\n",
    "### We can see HW3.2 faster than HW3.1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3.3  Only use 4 layer to train NN and add new softmax layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense3/Elu:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"logits_new/BiasAdd:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "# For AdamOptimizer\n",
    "learning_rate = 0.001\n",
    "n_classes = 5\n",
    "\n",
    "# import model from HW2\n",
    "restore_saver = tf.train.import_meta_graph(\"./hw2_model/Team20_HW2.ckpt.meta\")\n",
    "\n",
    "# Step1: Get tensor from HW2 model\n",
    "x = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"Y:0\")\n",
    "training_mode = tf.get_default_graph().get_tensor_by_name(\"is_training:0\")\n",
    "\n",
    "# Step2: Retrive the output of fourth layer\n",
    "fourth_dense_output = tf.get_default_graph().get_tensor_by_name(\"dense3/Elu:0\")\n",
    "print(fourth_dense_output)\n",
    "\n",
    "# And Make a new softmax layers\n",
    "logits = tf.layers.dense(inputs=fourth_dense_output, units=n_classes, kernel_initializer=\n",
    "                                    tf.contrib.layers.variance_scaling_initializer(), name='logits_new')\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits, name='sparse_cross_entropy')\n",
    "loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "\n",
    "# Step3: Only let softmax layer trainable\n",
    "output_layer = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='logits_new')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name='opt3_3')\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer)\n",
    "\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(logits, 1, output_type=tf.int32)\n",
    "correct_prediction = tf.equal(prediction, tf.cast(y, tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For initialize\n",
    "init_g = tf.global_variables_initializer()\n",
    "\n",
    "# Saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./hw2_model/Team20_HW2.ckpt\n",
      "Epoch 0: Validation loss: 3.7095155715942383 Best loss: 3.7095155715942383 Accuracy: 0.14666667580604553 \n",
      "Epoch 1: Validation loss: 3.4455342292785645 Best loss: 3.4455342292785645 Accuracy: 0.1666666567325592 \n",
      "Epoch 2: Validation loss: 3.1958770751953125 Best loss: 3.1958770751953125 Accuracy: 0.19333332777023315 \n",
      "Epoch 3: Validation loss: 2.9606239795684814 Best loss: 2.9606239795684814 Accuracy: 0.24000000953674316 \n",
      "Epoch 4: Validation loss: 2.740607261657715 Best loss: 2.740607261657715 Accuracy: 0.25999999046325684 \n",
      "Epoch 5: Validation loss: 2.5368072986602783 Best loss: 2.5368072986602783 Accuracy: 0.2866666615009308 \n",
      "Epoch 6: Validation loss: 2.3499741554260254 Best loss: 2.3499741554260254 Accuracy: 0.36666664481163025 \n",
      "Epoch 7: Validation loss: 2.1803154945373535 Best loss: 2.1803154945373535 Accuracy: 0.3866666555404663 \n",
      "Epoch 8: Validation loss: 2.0273947715759277 Best loss: 2.0273947715759277 Accuracy: 0.40666663646698 \n",
      "Epoch 9: Validation loss: 1.8902453184127808 Best loss: 1.8902453184127808 Accuracy: 0.4466666579246521 \n",
      "Epoch 10: Validation loss: 1.7675648927688599 Best loss: 1.7675648927688599 Accuracy: 0.47333329916000366 \n",
      "Epoch 11: Validation loss: 1.6579039096832275 Best loss: 1.6579039096832275 Accuracy: 0.48666664958000183 \n",
      "Epoch 12: Validation loss: 1.5598151683807373 Best loss: 1.5598151683807373 Accuracy: 0.4933333098888397 \n",
      "Epoch 13: Validation loss: 1.4719573259353638 Best loss: 1.4719573259353638 Accuracy: 0.5066666603088379 \n",
      "Epoch 14: Validation loss: 1.393154501914978 Best loss: 1.393154501914978 Accuracy: 0.5266666412353516 \n",
      "Epoch 15: Validation loss: 1.3224109411239624 Best loss: 1.3224109411239624 Accuracy: 0.5333333015441895 \n",
      "Epoch 16: Validation loss: 1.2588919401168823 Best loss: 1.2588919401168823 Accuracy: 0.559999942779541 \n",
      "Epoch 17: Validation loss: 1.201882004737854 Best loss: 1.201882004737854 Accuracy: 0.59333336353302 \n",
      "Epoch 18: Validation loss: 1.1507359743118286 Best loss: 1.1507359743118286 Accuracy: 0.6133333444595337 \n",
      "Epoch 19: Validation loss: 1.1048403978347778 Best loss: 1.1048403978347778 Accuracy: 0.6266666650772095 \n",
      "Epoch 20: Validation loss: 1.0635995864868164 Best loss: 1.0635995864868164 Accuracy: 0.6399999856948853 \n",
      "Epoch 21: Validation loss: 1.0264428853988647 Best loss: 1.0264428853988647 Accuracy: 0.6466666460037231 \n",
      "Epoch 22: Validation loss: 0.9928417205810547 Best loss: 0.9928417205810547 Accuracy: 0.6599999666213989 \n",
      "Epoch 23: Validation loss: 0.9623238444328308 Best loss: 0.9623238444328308 Accuracy: 0.6733333468437195 \n",
      "Epoch 24: Validation loss: 0.9344797730445862 Best loss: 0.9344797730445862 Accuracy: 0.6800000071525574 \n",
      "Epoch 25: Validation loss: 0.908961296081543 Best loss: 0.908961296081543 Accuracy: 0.7066666483879089 \n",
      "Epoch 26: Validation loss: 0.8854752779006958 Best loss: 0.8854752779006958 Accuracy: 0.7266666889190674 \n",
      "Epoch 27: Validation loss: 0.8637756705284119 Best loss: 0.8637756705284119 Accuracy: 0.7400000095367432 \n",
      "Epoch 28: Validation loss: 0.8436557650566101 Best loss: 0.8436557650566101 Accuracy: 0.7400000095367432 \n",
      "Epoch 29: Validation loss: 0.8249406814575195 Best loss: 0.8249406814575195 Accuracy: 0.753333330154419 \n",
      "Epoch 30: Validation loss: 0.8074820637702942 Best loss: 0.8074820637702942 Accuracy: 0.753333330154419 \n",
      "Epoch 31: Validation loss: 0.7911523580551147 Best loss: 0.7911523580551147 Accuracy: 0.7733333110809326 \n",
      "Epoch 32: Validation loss: 0.775841236114502 Best loss: 0.775841236114502 Accuracy: 0.7733333110809326 \n",
      "Epoch 33: Validation loss: 0.7614527940750122 Best loss: 0.7614527940750122 Accuracy: 0.7799999713897705 \n",
      "Epoch 34: Validation loss: 0.7479026317596436 Best loss: 0.7479026317596436 Accuracy: 0.7799999713897705 \n",
      "Epoch 35: Validation loss: 0.7351163625717163 Best loss: 0.7351163625717163 Accuracy: 0.7866666316986084 \n",
      "Epoch 36: Validation loss: 0.7230275869369507 Best loss: 0.7230275869369507 Accuracy: 0.7999999523162842 \n",
      "Epoch 37: Validation loss: 0.7115771770477295 Best loss: 0.7115771770477295 Accuracy: 0.7999999523162842 \n",
      "Epoch 38: Validation loss: 0.7007120251655579 Best loss: 0.7007120251655579 Accuracy: 0.7999999523162842 \n",
      "Epoch 39: Validation loss: 0.6903840899467468 Best loss: 0.6903840899467468 Accuracy: 0.8066666126251221 \n",
      "Epoch 40: Validation loss: 0.6805505752563477 Best loss: 0.6805505752563477 Accuracy: 0.8066666126251221 \n",
      "Epoch 41: Validation loss: 0.6711722016334534 Best loss: 0.6711722016334534 Accuracy: 0.8066666126251221 \n",
      "Epoch 42: Validation loss: 0.6622137427330017 Best loss: 0.6622137427330017 Accuracy: 0.81333327293396 \n",
      "Epoch 43: Validation loss: 0.6536429524421692 Best loss: 0.6536429524421692 Accuracy: 0.81333327293396 \n",
      "Epoch 44: Validation loss: 0.6454310417175293 Best loss: 0.6454310417175293 Accuracy: 0.8199999332427979 \n",
      "Epoch 45: Validation loss: 0.6375516057014465 Best loss: 0.6375516057014465 Accuracy: 0.8199999332427979 \n",
      "Epoch 46: Validation loss: 0.6299805045127869 Best loss: 0.6299805045127869 Accuracy: 0.81333327293396 \n",
      "Epoch 47: Validation loss: 0.6226963400840759 Best loss: 0.6226963400840759 Accuracy: 0.81333327293396 \n",
      "Epoch 48: Validation loss: 0.6156792640686035 Best loss: 0.6156792640686035 Accuracy: 0.8199999928474426 \n",
      "Epoch 49: Validation loss: 0.6089112758636475 Best loss: 0.6089112758636475 Accuracy: 0.8266665935516357 \n",
      "Epoch 50: Validation loss: 0.602376401424408 Best loss: 0.602376401424408 Accuracy: 0.8266665935516357 \n",
      "Epoch 51: Validation loss: 0.5960599184036255 Best loss: 0.5960599184036255 Accuracy: 0.8333333730697632 \n",
      "Epoch 52: Validation loss: 0.5899483561515808 Best loss: 0.5899483561515808 Accuracy: 0.8333333730697632 \n",
      "Epoch 53: Validation loss: 0.5840297937393188 Best loss: 0.5840297937393188 Accuracy: 0.8266665935516357 \n",
      "Epoch 54: Validation loss: 0.5782933235168457 Best loss: 0.5782933235168457 Accuracy: 0.8266665935516357 \n",
      "Epoch 55: Validation loss: 0.5727288126945496 Best loss: 0.5727288126945496 Accuracy: 0.8333332538604736 \n",
      "Epoch 56: Validation loss: 0.5673273801803589 Best loss: 0.5673273801803589 Accuracy: 0.8266665935516357 \n",
      "Epoch 57: Validation loss: 0.5620808601379395 Best loss: 0.5620808601379395 Accuracy: 0.8266665935516357 \n",
      "Epoch 58: Validation loss: 0.5569817423820496 Best loss: 0.5569817423820496 Accuracy: 0.8266665935516357 \n",
      "Epoch 59: Validation loss: 0.5520232915878296 Best loss: 0.5520232915878296 Accuracy: 0.8266665935516357 \n",
      "Epoch 60: Validation loss: 0.5471993088722229 Best loss: 0.5471993088722229 Accuracy: 0.8266665935516357 \n",
      "Epoch 61: Validation loss: 0.542504072189331 Best loss: 0.542504072189331 Accuracy: 0.8333333730697632 \n",
      "Epoch 62: Validation loss: 0.5379323959350586 Best loss: 0.5379323959350586 Accuracy: 0.8333333730697632 \n",
      "Epoch 63: Validation loss: 0.533479630947113 Best loss: 0.533479630947113 Accuracy: 0.8333333730697632 \n",
      "Epoch 64: Validation loss: 0.5291411280632019 Best loss: 0.5291411280632019 Accuracy: 0.8333332538604736 \n",
      "Epoch 65: Validation loss: 0.5249130129814148 Best loss: 0.5249130129814148 Accuracy: 0.8333332538604736 \n",
      "Epoch 66: Validation loss: 0.5207912921905518 Best loss: 0.5207912921905518 Accuracy: 0.8466665744781494 \n",
      "Epoch 67: Validation loss: 0.516772449016571 Best loss: 0.516772449016571 Accuracy: 0.8466665744781494 \n",
      "Epoch 68: Validation loss: 0.51285320520401 Best loss: 0.51285320520401 Accuracy: 0.8466665744781494 \n",
      "Epoch 69: Validation loss: 0.5090303421020508 Best loss: 0.5090303421020508 Accuracy: 0.8466665744781494 \n",
      "Epoch 70: Validation loss: 0.5053008794784546 Best loss: 0.5053008794784546 Accuracy: 0.8466665744781494 \n",
      "Epoch 71: Validation loss: 0.5016619563102722 Best loss: 0.5016619563102722 Accuracy: 0.8466665744781494 \n",
      "Epoch 72: Validation loss: 0.4981110394001007 Best loss: 0.4981110394001007 Accuracy: 0.8466665744781494 \n",
      "Epoch 73: Validation loss: 0.4946454167366028 Best loss: 0.4946454167366028 Accuracy: 0.8466665744781494 \n",
      "Epoch 74: Validation loss: 0.4912625849246979 Best loss: 0.4912625849246979 Accuracy: 0.8466665744781494 \n",
      "Epoch 75: Validation loss: 0.4879603385925293 Best loss: 0.4879603385925293 Accuracy: 0.8466665744781494 \n",
      "Epoch 76: Validation loss: 0.4847361445426941 Best loss: 0.4847361445426941 Accuracy: 0.8466665744781494 \n",
      "Epoch 77: Validation loss: 0.48158806562423706 Best loss: 0.48158806562423706 Accuracy: 0.8466665744781494 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Validation loss: 0.4785137474536896 Best loss: 0.4785137474536896 Accuracy: 0.8533332943916321 \n",
      "Epoch 79: Validation loss: 0.47551119327545166 Best loss: 0.47551119327545166 Accuracy: 0.8533332943916321 \n",
      "Epoch 80: Validation loss: 0.4725784361362457 Best loss: 0.4725784361362457 Accuracy: 0.8533332943916321 \n",
      "Epoch 81: Validation loss: 0.469713419675827 Best loss: 0.469713419675827 Accuracy: 0.8466666340827942 \n",
      "Epoch 82: Validation loss: 0.4669142961502075 Best loss: 0.4669142961502075 Accuracy: 0.8466666340827942 \n",
      "Epoch 83: Validation loss: 0.4641791880130768 Best loss: 0.4641791880130768 Accuracy: 0.8466666340827942 \n",
      "Epoch 84: Validation loss: 0.461506187915802 Best loss: 0.461506187915802 Accuracy: 0.8466666340827942 \n",
      "Epoch 85: Validation loss: 0.45889371633529663 Best loss: 0.45889371633529663 Accuracy: 0.8466666340827942 \n",
      "Epoch 86: Validation loss: 0.45633986592292786 Best loss: 0.45633986592292786 Accuracy: 0.8466666340827942 \n",
      "Epoch 87: Validation loss: 0.45384296774864197 Best loss: 0.45384296774864197 Accuracy: 0.8533333539962769 \n",
      "Epoch 88: Validation loss: 0.4514014422893524 Best loss: 0.4514014422893524 Accuracy: 0.8533333539962769 \n",
      "Epoch 89: Validation loss: 0.4490136206150055 Best loss: 0.4490136206150055 Accuracy: 0.8533333539962769 \n",
      "Epoch 90: Validation loss: 0.4466778635978699 Best loss: 0.4466778635978699 Accuracy: 0.8533333539962769 \n",
      "Epoch 91: Validation loss: 0.44439268112182617 Best loss: 0.44439268112182617 Accuracy: 0.8533333539962769 \n",
      "Epoch 92: Validation loss: 0.442156583070755 Best loss: 0.442156583070755 Accuracy: 0.8533333539962769 \n",
      "Epoch 93: Validation loss: 0.4399680197238922 Best loss: 0.4399680197238922 Accuracy: 0.8600000143051147 \n",
      "Epoch 94: Validation loss: 0.4378255605697632 Best loss: 0.4378255605697632 Accuracy: 0.8666666746139526 \n",
      "Epoch 95: Validation loss: 0.4357278048992157 Best loss: 0.4357278048992157 Accuracy: 0.85999995470047 \n",
      "Epoch 96: Validation loss: 0.4336734414100647 Best loss: 0.4336734414100647 Accuracy: 0.85999995470047 \n",
      "Epoch 97: Validation loss: 0.43166106939315796 Best loss: 0.43166106939315796 Accuracy: 0.85999995470047 \n",
      "Epoch 98: Validation loss: 0.42968934774398804 Best loss: 0.42968934774398804 Accuracy: 0.85999995470047 \n",
      "Epoch 99: Validation loss: 0.4277571141719818 Best loss: 0.4277571141719818 Accuracy: 0.85999995470047 \n",
      "Epoch 100: Validation loss: 0.4258630871772766 Best loss: 0.4258630871772766 Accuracy: 0.85999995470047 \n",
      "Epoch 101: Validation loss: 0.42400607466697693 Best loss: 0.42400607466697693 Accuracy: 0.85999995470047 \n",
      "Epoch 102: Validation loss: 0.42218488454818726 Best loss: 0.42218488454818726 Accuracy: 0.85999995470047 \n",
      "Epoch 103: Validation loss: 0.4203985333442688 Best loss: 0.4203985333442688 Accuracy: 0.85999995470047 \n",
      "Epoch 104: Validation loss: 0.4186457395553589 Best loss: 0.4186457395553589 Accuracy: 0.85999995470047 \n",
      "Epoch 105: Validation loss: 0.4169256389141083 Best loss: 0.4169256389141083 Accuracy: 0.85999995470047 \n",
      "Epoch 106: Validation loss: 0.4152371287345886 Best loss: 0.4152371287345886 Accuracy: 0.85999995470047 \n",
      "Epoch 107: Validation loss: 0.41357922554016113 Best loss: 0.41357922554016113 Accuracy: 0.85999995470047 \n",
      "Epoch 108: Validation loss: 0.4119510054588318 Best loss: 0.4119510054588318 Accuracy: 0.85999995470047 \n",
      "Epoch 109: Validation loss: 0.41035157442092896 Best loss: 0.41035157442092896 Accuracy: 0.85999995470047 \n",
      "Epoch 110: Validation loss: 0.4087800681591034 Best loss: 0.4087800681591034 Accuracy: 0.85999995470047 \n",
      "Epoch 111: Validation loss: 0.40723565220832825 Best loss: 0.40723565220832825 Accuracy: 0.85999995470047 \n",
      "Epoch 112: Validation loss: 0.40571755170822144 Best loss: 0.40571755170822144 Accuracy: 0.85999995470047 \n",
      "Epoch 113: Validation loss: 0.40422487258911133 Best loss: 0.40422487258911133 Accuracy: 0.85999995470047 \n",
      "Epoch 114: Validation loss: 0.40275701880455017 Best loss: 0.40275701880455017 Accuracy: 0.85999995470047 \n",
      "Epoch 115: Validation loss: 0.4013131260871887 Best loss: 0.4013131260871887 Accuracy: 0.85999995470047 \n",
      "Epoch 116: Validation loss: 0.3998927175998688 Best loss: 0.3998927175998688 Accuracy: 0.85999995470047 \n",
      "Epoch 117: Validation loss: 0.39849501848220825 Best loss: 0.39849501848220825 Accuracy: 0.85999995470047 \n",
      "Epoch 118: Validation loss: 0.3971194326877594 Best loss: 0.3971194326877594 Accuracy: 0.85999995470047 \n",
      "Epoch 119: Validation loss: 0.3957653343677521 Best loss: 0.3957653343677521 Accuracy: 0.85999995470047 \n",
      "Epoch 120: Validation loss: 0.3944321870803833 Best loss: 0.3944321870803833 Accuracy: 0.85999995470047 \n",
      "Epoch 121: Validation loss: 0.39311936497688293 Best loss: 0.39311936497688293 Accuracy: 0.85999995470047 \n",
      "Epoch 122: Validation loss: 0.39182648062705994 Best loss: 0.39182648062705994 Accuracy: 0.85999995470047 \n",
      "Epoch 123: Validation loss: 0.3905528783798218 Best loss: 0.3905528783798218 Accuracy: 0.85999995470047 \n",
      "Epoch 124: Validation loss: 0.38929829001426697 Best loss: 0.38929829001426697 Accuracy: 0.85999995470047 \n",
      "Epoch 125: Validation loss: 0.38806211948394775 Best loss: 0.38806211948394775 Accuracy: 0.85999995470047 \n",
      "Epoch 126: Validation loss: 0.38684386014938354 Best loss: 0.38684386014938354 Accuracy: 0.85999995470047 \n",
      "Epoch 127: Validation loss: 0.38564333319664 Best loss: 0.38564333319664 Accuracy: 0.85999995470047 \n",
      "Epoch 128: Validation loss: 0.38445988297462463 Best loss: 0.38445988297462463 Accuracy: 0.85999995470047 \n",
      "Epoch 129: Validation loss: 0.3832932710647583 Best loss: 0.3832932710647583 Accuracy: 0.85999995470047 \n",
      "Epoch 130: Validation loss: 0.3821430802345276 Best loss: 0.3821430802345276 Accuracy: 0.8666666746139526 \n",
      "Epoch 131: Validation loss: 0.38100898265838623 Best loss: 0.38100898265838623 Accuracy: 0.8733333349227905 \n",
      "Epoch 132: Validation loss: 0.37989071011543274 Best loss: 0.37989071011543274 Accuracy: 0.8733333349227905 \n",
      "Epoch 133: Validation loss: 0.3787877559661865 Best loss: 0.3787877559661865 Accuracy: 0.8733333349227905 \n",
      "Epoch 134: Validation loss: 0.37770000100135803 Best loss: 0.37770000100135803 Accuracy: 0.8799999952316284 \n",
      "Epoch 135: Validation loss: 0.3766270875930786 Best loss: 0.3766270875930786 Accuracy: 0.8799999952316284 \n",
      "Epoch 136: Validation loss: 0.3755686283111572 Best loss: 0.3755686283111572 Accuracy: 0.8799999952316284 \n",
      "Epoch 137: Validation loss: 0.37452447414398193 Best loss: 0.37452447414398193 Accuracy: 0.8799999952316284 \n",
      "Epoch 138: Validation loss: 0.37349429726600647 Best loss: 0.37349429726600647 Accuracy: 0.8799999952316284 \n",
      "Epoch 139: Validation loss: 0.37247779965400696 Best loss: 0.37247779965400696 Accuracy: 0.8866667151451111 \n",
      "Epoch 140: Validation loss: 0.37147486209869385 Best loss: 0.37147486209869385 Accuracy: 0.8866667151451111 \n",
      "Epoch 141: Validation loss: 0.3704851269721985 Best loss: 0.3704851269721985 Accuracy: 0.8866667151451111 \n",
      "Epoch 142: Validation loss: 0.36950844526290894 Best loss: 0.36950844526290894 Accuracy: 0.8866667151451111 \n",
      "Epoch 143: Validation loss: 0.36854442954063416 Best loss: 0.36854442954063416 Accuracy: 0.8866667151451111 \n",
      "Epoch 144: Validation loss: 0.36759307980537415 Best loss: 0.36759307980537415 Accuracy: 0.8866667151451111 \n",
      "Epoch 145: Validation loss: 0.36665406823158264 Best loss: 0.36665406823158264 Accuracy: 0.8866667151451111 \n",
      "Epoch 146: Validation loss: 0.36572715640068054 Best loss: 0.36572715640068054 Accuracy: 0.8866666555404663 \n",
      "Epoch 147: Validation loss: 0.3648121953010559 Best loss: 0.3648121953010559 Accuracy: 0.8800000548362732 \n",
      "Epoch 148: Validation loss: 0.36390894651412964 Best loss: 0.36390894651412964 Accuracy: 0.8800000548362732 \n",
      "Epoch 149: Validation loss: 0.3630172610282898 Best loss: 0.3630172610282898 Accuracy: 0.8800000548362732 \n",
      "Epoch 150: Validation loss: 0.36213698983192444 Best loss: 0.36213698983192444 Accuracy: 0.8800000548362732 \n",
      "Epoch 151: Validation loss: 0.3612678349018097 Best loss: 0.3612678349018097 Accuracy: 0.8800000548362732 \n",
      "Epoch 152: Validation loss: 0.360409677028656 Best loss: 0.360409677028656 Accuracy: 0.8800000548362732 \n",
      "Epoch 153: Validation loss: 0.35956233739852905 Best loss: 0.35956233739852905 Accuracy: 0.8799999952316284 \n",
      "Epoch 154: Validation loss: 0.3587256669998169 Best loss: 0.3587256669998169 Accuracy: 0.8800000548362732 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155: Validation loss: 0.35789942741394043 Best loss: 0.35789942741394043 Accuracy: 0.8800000548362732 \n",
      "Epoch 156: Validation loss: 0.3570835292339325 Best loss: 0.3570835292339325 Accuracy: 0.8800000548362732 \n",
      "Epoch 157: Validation loss: 0.3562777042388916 Best loss: 0.3562777042388916 Accuracy: 0.8800000548362732 \n",
      "Epoch 158: Validation loss: 0.35548198223114014 Best loss: 0.35548198223114014 Accuracy: 0.8800000548362732 \n",
      "Epoch 159: Validation loss: 0.3546959459781647 Best loss: 0.3546959459781647 Accuracy: 0.8800000548362732 \n",
      "Epoch 160: Validation loss: 0.35391974449157715 Best loss: 0.35391974449157715 Accuracy: 0.8800000548362732 \n",
      "Epoch 161: Validation loss: 0.3531529903411865 Best loss: 0.3531529903411865 Accuracy: 0.8800000548362732 \n",
      "Epoch 162: Validation loss: 0.35239556431770325 Best loss: 0.35239556431770325 Accuracy: 0.8800000548362732 \n",
      "Epoch 163: Validation loss: 0.35164737701416016 Best loss: 0.35164737701416016 Accuracy: 0.8800000548362732 \n",
      "Epoch 164: Validation loss: 0.3509083092212677 Best loss: 0.3509083092212677 Accuracy: 0.8800000548362732 \n",
      "Epoch 165: Validation loss: 0.35017815232276917 Best loss: 0.35017815232276917 Accuracy: 0.8800000548362732 \n",
      "Epoch 166: Validation loss: 0.34945687651634216 Best loss: 0.34945687651634216 Accuracy: 0.8800000548362732 \n",
      "Epoch 167: Validation loss: 0.34874415397644043 Best loss: 0.34874415397644043 Accuracy: 0.8800000548362732 \n",
      "Epoch 168: Validation loss: 0.34804004430770874 Best loss: 0.34804004430770874 Accuracy: 0.8800000548362732 \n",
      "Epoch 169: Validation loss: 0.3473443388938904 Best loss: 0.3473443388938904 Accuracy: 0.8800000548362732 \n",
      "Epoch 170: Validation loss: 0.346656858921051 Best loss: 0.346656858921051 Accuracy: 0.8800000548362732 \n",
      "Epoch 171: Validation loss: 0.3459774851799011 Best loss: 0.3459774851799011 Accuracy: 0.8800000548362732 \n",
      "Epoch 172: Validation loss: 0.3453061580657959 Best loss: 0.3453061580657959 Accuracy: 0.8800000548362732 \n",
      "Epoch 173: Validation loss: 0.3446427583694458 Best loss: 0.3446427583694458 Accuracy: 0.8800000548362732 \n",
      "Epoch 174: Validation loss: 0.3439871072769165 Best loss: 0.3439871072769165 Accuracy: 0.8800000548362732 \n",
      "Epoch 175: Validation loss: 0.34333914518356323 Best loss: 0.34333914518356323 Accuracy: 0.8800000548362732 \n",
      "Epoch 176: Validation loss: 0.3426986634731293 Best loss: 0.3426986634731293 Accuracy: 0.8800000548362732 \n",
      "Epoch 177: Validation loss: 0.34206557273864746 Best loss: 0.34206557273864746 Accuracy: 0.8800000548362732 \n",
      "Epoch 178: Validation loss: 0.3414398431777954 Best loss: 0.3414398431777954 Accuracy: 0.8800000548362732 \n",
      "Epoch 179: Validation loss: 0.3408212661743164 Best loss: 0.3408212661743164 Accuracy: 0.8800000548362732 \n",
      "Epoch 180: Validation loss: 0.3402097821235657 Best loss: 0.3402097821235657 Accuracy: 0.8800000548362732 \n",
      "Epoch 181: Validation loss: 0.33960530161857605 Best loss: 0.33960530161857605 Accuracy: 0.8800000548362732 \n",
      "Epoch 182: Validation loss: 0.33900773525238037 Best loss: 0.33900773525238037 Accuracy: 0.8866667151451111 \n",
      "Epoch 183: Validation loss: 0.33841681480407715 Best loss: 0.33841681480407715 Accuracy: 0.8866667151451111 \n",
      "Epoch 184: Validation loss: 0.33783257007598877 Best loss: 0.33783257007598877 Accuracy: 0.8866667151451111 \n",
      "Epoch 185: Validation loss: 0.33725494146347046 Best loss: 0.33725494146347046 Accuracy: 0.8866667151451111 \n",
      "Epoch 186: Validation loss: 0.3366837799549103 Best loss: 0.3366837799549103 Accuracy: 0.8866667151451111 \n",
      "Epoch 187: Validation loss: 0.33611905574798584 Best loss: 0.33611905574798584 Accuracy: 0.8866667151451111 \n",
      "Epoch 188: Validation loss: 0.33556047081947327 Best loss: 0.33556047081947327 Accuracy: 0.8866667151451111 \n",
      "Epoch 189: Validation loss: 0.33500808477401733 Best loss: 0.33500808477401733 Accuracy: 0.8866667151451111 \n",
      "Epoch 190: Validation loss: 0.33446183800697327 Best loss: 0.33446183800697327 Accuracy: 0.8866667151451111 \n",
      "Epoch 191: Validation loss: 0.3339216113090515 Best loss: 0.3339216113090515 Accuracy: 0.8866667151451111 \n",
      "Epoch 192: Validation loss: 0.33338725566864014 Best loss: 0.33338725566864014 Accuracy: 0.8866667151451111 \n",
      "Epoch 193: Validation loss: 0.33285871148109436 Best loss: 0.33285871148109436 Accuracy: 0.8866666555404663 \n",
      "Epoch 194: Validation loss: 0.3323359191417694 Best loss: 0.3323359191417694 Accuracy: 0.8866667151451111 \n",
      "Epoch 195: Validation loss: 0.3318188488483429 Best loss: 0.3318188488483429 Accuracy: 0.8866667151451111 \n",
      "Epoch 196: Validation loss: 0.3313072621822357 Best loss: 0.3313072621822357 Accuracy: 0.8866667151451111 \n",
      "Epoch 197: Validation loss: 0.33080124855041504 Best loss: 0.33080124855041504 Accuracy: 0.8866667151451111 \n",
      "Epoch 198: Validation loss: 0.33030062913894653 Best loss: 0.33030062913894653 Accuracy: 0.8800000548362732 \n",
      "Epoch 199: Validation loss: 0.3298053443431854 Best loss: 0.3298053443431854 Accuracy: 0.8733333349227905 \n",
      "Epoch 200: Validation loss: 0.32931530475616455 Best loss: 0.32931530475616455 Accuracy: 0.8733333349227905 \n",
      "Epoch 201: Validation loss: 0.3288305401802063 Best loss: 0.3288305401802063 Accuracy: 0.8733333349227905 \n",
      "Epoch 202: Validation loss: 0.32835081219673157 Best loss: 0.32835081219673157 Accuracy: 0.8733333349227905 \n",
      "Epoch 203: Validation loss: 0.3278762400150299 Best loss: 0.3278762400150299 Accuracy: 0.8733333349227905 \n",
      "Epoch 204: Validation loss: 0.3274065852165222 Best loss: 0.3274065852165222 Accuracy: 0.8733333349227905 \n",
      "Epoch 205: Validation loss: 0.3269417881965637 Best loss: 0.3269417881965637 Accuracy: 0.8733333349227905 \n",
      "Epoch 206: Validation loss: 0.3264819383621216 Best loss: 0.3264819383621216 Accuracy: 0.8733333349227905 \n",
      "Epoch 207: Validation loss: 0.3260267972946167 Best loss: 0.3260267972946167 Accuracy: 0.8733333349227905 \n",
      "Epoch 208: Validation loss: 0.32557639479637146 Best loss: 0.32557639479637146 Accuracy: 0.8733333349227905 \n",
      "Epoch 209: Validation loss: 0.3251306712627411 Best loss: 0.3251306712627411 Accuracy: 0.8733333349227905 \n",
      "Epoch 210: Validation loss: 0.3246895372867584 Best loss: 0.3246895372867584 Accuracy: 0.8733333349227905 \n",
      "Epoch 211: Validation loss: 0.3242529034614563 Best loss: 0.3242529034614563 Accuracy: 0.8733333349227905 \n",
      "Epoch 212: Validation loss: 0.32382073998451233 Best loss: 0.32382073998451233 Accuracy: 0.8733333349227905 \n",
      "Epoch 213: Validation loss: 0.3233930468559265 Best loss: 0.3233930468559265 Accuracy: 0.8733333349227905 \n",
      "Epoch 214: Validation loss: 0.3229696750640869 Best loss: 0.3229696750640869 Accuracy: 0.8733333349227905 \n",
      "Epoch 215: Validation loss: 0.32255053520202637 Best loss: 0.32255053520202637 Accuracy: 0.8733333349227905 \n",
      "Epoch 216: Validation loss: 0.32213568687438965 Best loss: 0.32213568687438965 Accuracy: 0.8800000548362732 \n",
      "Epoch 217: Validation loss: 0.3217250406742096 Best loss: 0.3217250406742096 Accuracy: 0.8800000548362732 \n",
      "Epoch 218: Validation loss: 0.32131853699684143 Best loss: 0.32131853699684143 Accuracy: 0.8800000548362732 \n",
      "Epoch 219: Validation loss: 0.3209160566329956 Best loss: 0.3209160566329956 Accuracy: 0.8800000548362732 \n",
      "Epoch 220: Validation loss: 0.3205175995826721 Best loss: 0.3205175995826721 Accuracy: 0.8799999952316284 \n",
      "Epoch 221: Validation loss: 0.32012316584587097 Best loss: 0.32012316584587097 Accuracy: 0.8800000548362732 \n",
      "Epoch 222: Validation loss: 0.319732666015625 Best loss: 0.319732666015625 Accuracy: 0.8800000548362732 \n",
      "Epoch 223: Validation loss: 0.3193460702896118 Best loss: 0.3193460702896118 Accuracy: 0.8800000548362732 \n",
      "Epoch 224: Validation loss: 0.31896325945854187 Best loss: 0.31896325945854187 Accuracy: 0.8800000548362732 \n",
      "Epoch 225: Validation loss: 0.31858423352241516 Best loss: 0.31858423352241516 Accuracy: 0.8866667151451111 \n",
      "Epoch 226: Validation loss: 0.3182089626789093 Best loss: 0.3182089626789093 Accuracy: 0.8866667151451111 \n",
      "Epoch 227: Validation loss: 0.3178373873233795 Best loss: 0.3178373873233795 Accuracy: 0.8866667151451111 \n",
      "Epoch 228: Validation loss: 0.3174695074558258 Best loss: 0.3174695074558258 Accuracy: 0.8866667151451111 \n",
      "Epoch 229: Validation loss: 0.31710517406463623 Best loss: 0.31710517406463623 Accuracy: 0.8866667151451111 \n",
      "Epoch 230: Validation loss: 0.3167444169521332 Best loss: 0.3167444169521332 Accuracy: 0.8866667151451111 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231: Validation loss: 0.3163871765136719 Best loss: 0.3163871765136719 Accuracy: 0.8866667151451111 \n",
      "Epoch 232: Validation loss: 0.3160334527492523 Best loss: 0.3160334527492523 Accuracy: 0.8866667151451111 \n",
      "Epoch 233: Validation loss: 0.31568315625190735 Best loss: 0.31568315625190735 Accuracy: 0.8866667151451111 \n",
      "Epoch 234: Validation loss: 0.3153362572193146 Best loss: 0.3153362572193146 Accuracy: 0.8866667151451111 \n",
      "Epoch 235: Validation loss: 0.3149926960468292 Best loss: 0.3149926960468292 Accuracy: 0.8866667151451111 \n",
      "Epoch 236: Validation loss: 0.3146525025367737 Best loss: 0.3146525025367737 Accuracy: 0.8866667151451111 \n",
      "Epoch 237: Validation loss: 0.3143155574798584 Best loss: 0.3143155574798584 Accuracy: 0.8866667151451111 \n",
      "Epoch 238: Validation loss: 0.31398189067840576 Best loss: 0.31398189067840576 Accuracy: 0.8866667151451111 \n",
      "Epoch 239: Validation loss: 0.313651442527771 Best loss: 0.313651442527771 Accuracy: 0.8866667151451111 \n",
      "Epoch 240: Validation loss: 0.31332412362098694 Best loss: 0.31332412362098694 Accuracy: 0.8866667151451111 \n",
      "Epoch 241: Validation loss: 0.31299999356269836 Best loss: 0.31299999356269836 Accuracy: 0.8866667151451111 \n",
      "Epoch 242: Validation loss: 0.3126789629459381 Best loss: 0.3126789629459381 Accuracy: 0.8866667151451111 \n",
      "Epoch 243: Validation loss: 0.3123609721660614 Best loss: 0.3123609721660614 Accuracy: 0.8866667151451111 \n",
      "Epoch 244: Validation loss: 0.3120460510253906 Best loss: 0.3120460510253906 Accuracy: 0.8866667151451111 \n",
      "Epoch 245: Validation loss: 0.3117341697216034 Best loss: 0.3117341697216034 Accuracy: 0.8866667151451111 \n",
      "Epoch 246: Validation loss: 0.31142523884773254 Best loss: 0.31142523884773254 Accuracy: 0.8866667151451111 \n",
      "Epoch 247: Validation loss: 0.31111928820610046 Best loss: 0.31111928820610046 Accuracy: 0.8866667151451111 \n",
      "Epoch 248: Validation loss: 0.3108161389827728 Best loss: 0.3108161389827728 Accuracy: 0.8866667151451111 \n",
      "Epoch 249: Validation loss: 0.31051599979400635 Best loss: 0.31051599979400635 Accuracy: 0.8866667151451111 \n",
      "Epoch 250: Validation loss: 0.3102186918258667 Best loss: 0.3102186918258667 Accuracy: 0.8866667151451111 \n",
      "Epoch 251: Validation loss: 0.3099241852760315 Best loss: 0.3099241852760315 Accuracy: 0.8866667151451111 \n",
      "Epoch 252: Validation loss: 0.30963248014450073 Best loss: 0.30963248014450073 Accuracy: 0.8866667151451111 \n",
      "Epoch 253: Validation loss: 0.30934351682662964 Best loss: 0.30934351682662964 Accuracy: 0.8800000548362732 \n",
      "Epoch 254: Validation loss: 0.3090573251247406 Best loss: 0.3090573251247406 Accuracy: 0.8800000548362732 \n",
      "Epoch 255: Validation loss: 0.30877384543418884 Best loss: 0.30877384543418884 Accuracy: 0.8800000548362732 \n",
      "Epoch 256: Validation loss: 0.30849307775497437 Best loss: 0.30849307775497437 Accuracy: 0.8800000548362732 \n",
      "Epoch 257: Validation loss: 0.30821493268013 Best loss: 0.30821493268013 Accuracy: 0.8800000548362732 \n",
      "Epoch 258: Validation loss: 0.30793946981430054 Best loss: 0.30793946981430054 Accuracy: 0.8800000548362732 \n",
      "Epoch 259: Validation loss: 0.3076666295528412 Best loss: 0.3076666295528412 Accuracy: 0.8800000548362732 \n",
      "Epoch 260: Validation loss: 0.3073962926864624 Best loss: 0.3073962926864624 Accuracy: 0.8800000548362732 \n",
      "Epoch 261: Validation loss: 0.30712857842445374 Best loss: 0.30712857842445374 Accuracy: 0.8800000548362732 \n",
      "Epoch 262: Validation loss: 0.306863397359848 Best loss: 0.306863397359848 Accuracy: 0.8800000548362732 \n",
      "Epoch 263: Validation loss: 0.30660074949264526 Best loss: 0.30660074949264526 Accuracy: 0.8800000548362732 \n",
      "Epoch 264: Validation loss: 0.3063405752182007 Best loss: 0.3063405752182007 Accuracy: 0.8800000548362732 \n",
      "Epoch 265: Validation loss: 0.3060828447341919 Best loss: 0.3060828447341919 Accuracy: 0.8800000548362732 \n",
      "Epoch 266: Validation loss: 0.30582761764526367 Best loss: 0.30582761764526367 Accuracy: 0.8799999952316284 \n",
      "Epoch 267: Validation loss: 0.30557480454444885 Best loss: 0.30557480454444885 Accuracy: 0.8800000548362732 \n",
      "Epoch 268: Validation loss: 0.30532440543174744 Best loss: 0.30532440543174744 Accuracy: 0.8800000548362732 \n",
      "Epoch 269: Validation loss: 0.30507636070251465 Best loss: 0.30507636070251465 Accuracy: 0.8800000548362732 \n",
      "Epoch 270: Validation loss: 0.30483072996139526 Best loss: 0.30483072996139526 Accuracy: 0.8800000548362732 \n",
      "Epoch 271: Validation loss: 0.30458733439445496 Best loss: 0.30458733439445496 Accuracy: 0.8800000548362732 \n",
      "Epoch 272: Validation loss: 0.3043462932109833 Best loss: 0.3043462932109833 Accuracy: 0.8800000548362732 \n",
      "Epoch 273: Validation loss: 0.304107666015625 Best loss: 0.304107666015625 Accuracy: 0.8800000548362732 \n",
      "Epoch 274: Validation loss: 0.303871214389801 Best loss: 0.303871214389801 Accuracy: 0.8800000548362732 \n",
      "Epoch 275: Validation loss: 0.3036370575428009 Best loss: 0.3036370575428009 Accuracy: 0.8800000548362732 \n",
      "Epoch 276: Validation loss: 0.30340516567230225 Best loss: 0.30340516567230225 Accuracy: 0.8800000548362732 \n",
      "Epoch 277: Validation loss: 0.30317550897598267 Best loss: 0.30317550897598267 Accuracy: 0.8800000548362732 \n",
      "Epoch 278: Validation loss: 0.3029480576515198 Best loss: 0.3029480576515198 Accuracy: 0.8800000548362732 \n",
      "Epoch 279: Validation loss: 0.3027227818965912 Best loss: 0.3027227818965912 Accuracy: 0.8800000548362732 \n",
      "Epoch 280: Validation loss: 0.3024997413158417 Best loss: 0.3024997413158417 Accuracy: 0.8800000548362732 \n",
      "Epoch 281: Validation loss: 0.3022788166999817 Best loss: 0.3022788166999817 Accuracy: 0.8800000548362732 \n",
      "Epoch 282: Validation loss: 0.30205997824668884 Best loss: 0.30205997824668884 Accuracy: 0.8800000548362732 \n",
      "Epoch 283: Validation loss: 0.3018433749675751 Best loss: 0.3018433749675751 Accuracy: 0.8800000548362732 \n",
      "Epoch 284: Validation loss: 0.30162882804870605 Best loss: 0.30162882804870605 Accuracy: 0.8800000548362732 \n",
      "Epoch 285: Validation loss: 0.30141639709472656 Best loss: 0.30141639709472656 Accuracy: 0.8800000548362732 \n",
      "Epoch 286: Validation loss: 0.3012060225009918 Best loss: 0.3012060225009918 Accuracy: 0.8800000548362732 \n",
      "Epoch 287: Validation loss: 0.30099767446517944 Best loss: 0.30099767446517944 Accuracy: 0.8800000548362732 \n",
      "Epoch 288: Validation loss: 0.300791472196579 Best loss: 0.300791472196579 Accuracy: 0.8800000548362732 \n",
      "Epoch 289: Validation loss: 0.30058732628822327 Best loss: 0.30058732628822327 Accuracy: 0.8800000548362732 \n",
      "Epoch 290: Validation loss: 0.300385057926178 Best loss: 0.300385057926178 Accuracy: 0.8800000548362732 \n",
      "Epoch 291: Validation loss: 0.30018487572669983 Best loss: 0.30018487572669983 Accuracy: 0.8800000548362732 \n",
      "Epoch 292: Validation loss: 0.29998674988746643 Best loss: 0.29998674988746643 Accuracy: 0.8800000548362732 \n",
      "Epoch 293: Validation loss: 0.29979047179222107 Best loss: 0.29979047179222107 Accuracy: 0.8800000548362732 \n",
      "Epoch 294: Validation loss: 0.29959622025489807 Best loss: 0.29959622025489807 Accuracy: 0.8800000548362732 \n",
      "Epoch 295: Validation loss: 0.2994039058685303 Best loss: 0.2994039058685303 Accuracy: 0.8800000548362732 \n",
      "Epoch 296: Validation loss: 0.29921355843544006 Best loss: 0.29921355843544006 Accuracy: 0.8800000548362732 \n",
      "Epoch 297: Validation loss: 0.2990250587463379 Best loss: 0.2990250587463379 Accuracy: 0.8800000548362732 \n",
      "Epoch 298: Validation loss: 0.2988385856151581 Best loss: 0.2988385856151581 Accuracy: 0.8800000548362732 \n",
      "Epoch 299: Validation loss: 0.2986539900302887 Best loss: 0.2986539900302887 Accuracy: 0.8800000548362732 \n",
      "Epoch 300: Validation loss: 0.2984711825847626 Best loss: 0.2984711825847626 Accuracy: 0.8800000548362732 \n",
      "Epoch 301: Validation loss: 0.29829034209251404 Best loss: 0.29829034209251404 Accuracy: 0.8800000548362732 \n",
      "Epoch 302: Validation loss: 0.29811134934425354 Best loss: 0.29811134934425354 Accuracy: 0.8800000548362732 \n",
      "Epoch 303: Validation loss: 0.2979341745376587 Best loss: 0.2979341745376587 Accuracy: 0.8800000548362732 \n",
      "Epoch 304: Validation loss: 0.29775887727737427 Best loss: 0.29775887727737427 Accuracy: 0.8800000548362732 \n",
      "Epoch 305: Validation loss: 0.2975853681564331 Best loss: 0.2975853681564331 Accuracy: 0.8800000548362732 \n",
      "Epoch 306: Validation loss: 0.29741373658180237 Best loss: 0.29741373658180237 Accuracy: 0.8800000548362732 \n",
      "Epoch 307: Validation loss: 0.2972438931465149 Best loss: 0.2972438931465149 Accuracy: 0.8799999952316284 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308: Validation loss: 0.2970758378505707 Best loss: 0.2970758378505707 Accuracy: 0.8800000548362732 \n",
      "Epoch 309: Validation loss: 0.29690951108932495 Best loss: 0.29690951108932495 Accuracy: 0.8800000548362732 \n",
      "Epoch 310: Validation loss: 0.2967450022697449 Best loss: 0.2967450022697449 Accuracy: 0.8799999952316284 \n",
      "Epoch 311: Validation loss: 0.29658228158950806 Best loss: 0.29658228158950806 Accuracy: 0.8800000548362732 \n",
      "Epoch 312: Validation loss: 0.29642120003700256 Best loss: 0.29642120003700256 Accuracy: 0.8800000548362732 \n",
      "Epoch 313: Validation loss: 0.2962619662284851 Best loss: 0.2962619662284851 Accuracy: 0.8800000548362732 \n",
      "Epoch 314: Validation loss: 0.29610440135002136 Best loss: 0.29610440135002136 Accuracy: 0.8800000548362732 \n",
      "Epoch 315: Validation loss: 0.29594865441322327 Best loss: 0.29594865441322327 Accuracy: 0.8800000548362732 \n",
      "Epoch 316: Validation loss: 0.2957945466041565 Best loss: 0.2957945466041565 Accuracy: 0.8800000548362732 \n",
      "Epoch 317: Validation loss: 0.2956421375274658 Best loss: 0.2956421375274658 Accuracy: 0.8800000548362732 \n",
      "Epoch 318: Validation loss: 0.29549136757850647 Best loss: 0.29549136757850647 Accuracy: 0.8800000548362732 \n",
      "Epoch 319: Validation loss: 0.2953423857688904 Best loss: 0.2953423857688904 Accuracy: 0.8800000548362732 \n",
      "Epoch 320: Validation loss: 0.2951950430870056 Best loss: 0.2951950430870056 Accuracy: 0.8800000548362732 \n",
      "Epoch 321: Validation loss: 0.29504939913749695 Best loss: 0.29504939913749695 Accuracy: 0.8800000548362732 \n",
      "Epoch 322: Validation loss: 0.29490527510643005 Best loss: 0.29490527510643005 Accuracy: 0.8800000548362732 \n",
      "Epoch 323: Validation loss: 0.29476287961006165 Best loss: 0.29476287961006165 Accuracy: 0.8800000548362732 \n",
      "Epoch 324: Validation loss: 0.2946220934391022 Best loss: 0.2946220934391022 Accuracy: 0.8800000548362732 \n",
      "Epoch 325: Validation loss: 0.294482946395874 Best loss: 0.294482946395874 Accuracy: 0.8800000548362732 \n",
      "Epoch 326: Validation loss: 0.2943454384803772 Best loss: 0.2943454384803772 Accuracy: 0.8800000548362732 \n",
      "Epoch 327: Validation loss: 0.29420948028564453 Best loss: 0.29420948028564453 Accuracy: 0.8800000548362732 \n",
      "Epoch 328: Validation loss: 0.2940751314163208 Best loss: 0.2940751314163208 Accuracy: 0.8800000548362732 \n",
      "Epoch 329: Validation loss: 0.2939424216747284 Best loss: 0.2939424216747284 Accuracy: 0.8800000548362732 \n",
      "Epoch 330: Validation loss: 0.29381126165390015 Best loss: 0.29381126165390015 Accuracy: 0.8866667151451111 \n",
      "Epoch 331: Validation loss: 0.29368165135383606 Best loss: 0.29368165135383606 Accuracy: 0.8866667151451111 \n",
      "Epoch 332: Validation loss: 0.2935536205768585 Best loss: 0.2935536205768585 Accuracy: 0.8866667151451111 \n",
      "Epoch 333: Validation loss: 0.2934271991252899 Best loss: 0.2934271991252899 Accuracy: 0.8866667151451111 \n",
      "Epoch 334: Validation loss: 0.2933022379875183 Best loss: 0.2933022379875183 Accuracy: 0.8866667151451111 \n",
      "Epoch 335: Validation loss: 0.29317888617515564 Best loss: 0.29317888617515564 Accuracy: 0.8866667151451111 \n",
      "Epoch 336: Validation loss: 0.29305705428123474 Best loss: 0.29305705428123474 Accuracy: 0.8866667151451111 \n",
      "Epoch 337: Validation loss: 0.2929367423057556 Best loss: 0.2929367423057556 Accuracy: 0.8866667151451111 \n",
      "Epoch 338: Validation loss: 0.2928179204463959 Best loss: 0.2928179204463959 Accuracy: 0.8866667151451111 \n",
      "Epoch 339: Validation loss: 0.2927005887031555 Best loss: 0.2927005887031555 Accuracy: 0.8866667151451111 \n",
      "Epoch 340: Validation loss: 0.2925848364830017 Best loss: 0.2925848364830017 Accuracy: 0.8866667151451111 \n",
      "Epoch 341: Validation loss: 0.2924705147743225 Best loss: 0.2924705147743225 Accuracy: 0.8866667151451111 \n",
      "Epoch 342: Validation loss: 0.2923576533794403 Best loss: 0.2923576533794403 Accuracy: 0.8866667151451111 \n",
      "Epoch 343: Validation loss: 0.2922462821006775 Best loss: 0.2922462821006775 Accuracy: 0.8866667151451111 \n",
      "Epoch 344: Validation loss: 0.29213640093803406 Best loss: 0.29213640093803406 Accuracy: 0.8866667151451111 \n",
      "Epoch 345: Validation loss: 0.29202800989151 Best loss: 0.29202800989151 Accuracy: 0.8866667151451111 \n",
      "Epoch 346: Validation loss: 0.29192104935646057 Best loss: 0.29192104935646057 Accuracy: 0.8866667151451111 \n",
      "Epoch 347: Validation loss: 0.29181551933288574 Best loss: 0.29181551933288574 Accuracy: 0.8866667151451111 \n",
      "Epoch 348: Validation loss: 0.2917114198207855 Best loss: 0.2917114198207855 Accuracy: 0.8866667151451111 \n",
      "Epoch 349: Validation loss: 0.2916087210178375 Best loss: 0.2916087210178375 Accuracy: 0.8866667151451111 \n",
      "Epoch 350: Validation loss: 0.2915075421333313 Best loss: 0.2915075421333313 Accuracy: 0.8866667151451111 \n",
      "Epoch 351: Validation loss: 0.2914077043533325 Best loss: 0.2914077043533325 Accuracy: 0.893333375453949 \n",
      "Epoch 352: Validation loss: 0.29130932688713074 Best loss: 0.29130932688713074 Accuracy: 0.893333375453949 \n",
      "Epoch 353: Validation loss: 0.2912123501300812 Best loss: 0.2912123501300812 Accuracy: 0.893333375453949 \n",
      "Epoch 354: Validation loss: 0.29111677408218384 Best loss: 0.29111677408218384 Accuracy: 0.893333375453949 \n",
      "Epoch 355: Validation loss: 0.29102253913879395 Best loss: 0.29102253913879395 Accuracy: 0.893333375453949 \n",
      "Epoch 356: Validation loss: 0.2909296751022339 Best loss: 0.2909296751022339 Accuracy: 0.893333375453949 \n",
      "Epoch 357: Validation loss: 0.29083821177482605 Best loss: 0.29083821177482605 Accuracy: 0.893333375453949 \n",
      "Epoch 358: Validation loss: 0.2907481789588928 Best loss: 0.2907481789588928 Accuracy: 0.893333375453949 \n",
      "Epoch 359: Validation loss: 0.2906593680381775 Best loss: 0.2906593680381775 Accuracy: 0.9000000357627869 \n",
      "Epoch 360: Validation loss: 0.29057207703590393 Best loss: 0.29057207703590393 Accuracy: 0.9000000357627869 \n",
      "Epoch 361: Validation loss: 0.29048600792884827 Best loss: 0.29048600792884827 Accuracy: 0.9000000357627869 \n",
      "Epoch 362: Validation loss: 0.2904013395309448 Best loss: 0.2904013395309448 Accuracy: 0.9000000357627869 \n",
      "Epoch 363: Validation loss: 0.29031795263290405 Best loss: 0.29031795263290405 Accuracy: 0.9000000357627869 \n",
      "Epoch 364: Validation loss: 0.2902359068393707 Best loss: 0.2902359068393707 Accuracy: 0.9000000357627869 \n",
      "Epoch 365: Validation loss: 0.29015523195266724 Best loss: 0.29015523195266724 Accuracy: 0.9000000357627869 \n",
      "Epoch 366: Validation loss: 0.2900758385658264 Best loss: 0.2900758385658264 Accuracy: 0.9000000357627869 \n",
      "Epoch 367: Validation loss: 0.28999772667884827 Best loss: 0.28999772667884827 Accuracy: 0.9000000357627869 \n",
      "Epoch 368: Validation loss: 0.2899209260940552 Best loss: 0.2899209260940552 Accuracy: 0.9000000357627869 \n",
      "Epoch 369: Validation loss: 0.2898454964160919 Best loss: 0.2898454964160919 Accuracy: 0.9000000357627869 \n",
      "Epoch 370: Validation loss: 0.28977128863334656 Best loss: 0.28977128863334656 Accuracy: 0.9000000357627869 \n",
      "Epoch 371: Validation loss: 0.28969836235046387 Best loss: 0.28969836235046387 Accuracy: 0.9000000357627869 \n",
      "Epoch 372: Validation loss: 0.2896266579627991 Best loss: 0.2896266579627991 Accuracy: 0.9000000357627869 \n",
      "Epoch 373: Validation loss: 0.2895563542842865 Best loss: 0.2895563542842865 Accuracy: 0.9000000357627869 \n",
      "Epoch 374: Validation loss: 0.28948724269866943 Best loss: 0.28948724269866943 Accuracy: 0.9000000357627869 \n",
      "Epoch 375: Validation loss: 0.28941935300827026 Best loss: 0.28941935300827026 Accuracy: 0.9000000357627869 \n",
      "Epoch 376: Validation loss: 0.28935277462005615 Best loss: 0.28935277462005615 Accuracy: 0.9000000357627869 \n",
      "Epoch 377: Validation loss: 0.2892873287200928 Best loss: 0.2892873287200928 Accuracy: 0.9000000357627869 \n",
      "Epoch 378: Validation loss: 0.28922322392463684 Best loss: 0.28922322392463684 Accuracy: 0.9000000357627869 \n",
      "Epoch 379: Validation loss: 0.28916028141975403 Best loss: 0.28916028141975403 Accuracy: 0.9000000357627869 \n",
      "Epoch 380: Validation loss: 0.28909868001937866 Best loss: 0.28909868001937866 Accuracy: 0.9000000357627869 \n",
      "Epoch 381: Validation loss: 0.28903818130493164 Best loss: 0.28903818130493164 Accuracy: 0.9000000357627869 \n",
      "Epoch 382: Validation loss: 0.2889789938926697 Best loss: 0.2889789938926697 Accuracy: 0.9000000357627869 \n",
      "Epoch 383: Validation loss: 0.28892090916633606 Best loss: 0.28892090916633606 Accuracy: 0.9000000357627869 \n",
      "Epoch 384: Validation loss: 0.2888640761375427 Best loss: 0.2888640761375427 Accuracy: 0.9000000357627869 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385: Validation loss: 0.2888084053993225 Best loss: 0.2888084053993225 Accuracy: 0.9000000357627869 \n",
      "Epoch 386: Validation loss: 0.2887539863586426 Best loss: 0.2887539863586426 Accuracy: 0.9000000357627869 \n",
      "Epoch 387: Validation loss: 0.288700670003891 Best loss: 0.288700670003891 Accuracy: 0.9000000357627869 \n",
      "Epoch 388: Validation loss: 0.2886486053466797 Best loss: 0.2886486053466797 Accuracy: 0.9000000357627869 \n",
      "Epoch 389: Validation loss: 0.2885977029800415 Best loss: 0.2885977029800415 Accuracy: 0.9000000357627869 \n",
      "Epoch 390: Validation loss: 0.2885478436946869 Best loss: 0.2885478436946869 Accuracy: 0.9000000357627869 \n",
      "Epoch 391: Validation loss: 0.2884993553161621 Best loss: 0.2884993553161621 Accuracy: 0.893333375453949 \n",
      "Epoch 392: Validation loss: 0.28845182061195374 Best loss: 0.28845182061195374 Accuracy: 0.893333375453949 \n",
      "Epoch 393: Validation loss: 0.28840553760528564 Best loss: 0.28840553760528564 Accuracy: 0.893333375453949 \n",
      "Epoch 394: Validation loss: 0.2883603572845459 Best loss: 0.2883603572845459 Accuracy: 0.893333375453949 \n",
      "Epoch 395: Validation loss: 0.2883163094520569 Best loss: 0.2883163094520569 Accuracy: 0.893333375453949 \n",
      "Epoch 396: Validation loss: 0.2882733941078186 Best loss: 0.2882733941078186 Accuracy: 0.893333375453949 \n",
      "Epoch 397: Validation loss: 0.28823164105415344 Best loss: 0.28823164105415344 Accuracy: 0.893333375453949 \n",
      "Epoch 398: Validation loss: 0.28819096088409424 Best loss: 0.28819096088409424 Accuracy: 0.893333375453949 \n",
      "Epoch 399: Validation loss: 0.28815141320228577 Best loss: 0.28815141320228577 Accuracy: 0.893333375453949 \n",
      "Epoch 400: Validation loss: 0.28811296820640564 Best loss: 0.28811296820640564 Accuracy: 0.8933333158493042 \n",
      "Epoch 401: Validation loss: 0.28807562589645386 Best loss: 0.28807562589645386 Accuracy: 0.893333375453949 \n",
      "Epoch 402: Validation loss: 0.28803932666778564 Best loss: 0.28803932666778564 Accuracy: 0.893333375453949 \n",
      "Epoch 403: Validation loss: 0.2880042493343353 Best loss: 0.2880042493343353 Accuracy: 0.893333375453949 \n",
      "Epoch 404: Validation loss: 0.2879701256752014 Best loss: 0.2879701256752014 Accuracy: 0.893333375453949 \n",
      "Epoch 405: Validation loss: 0.28793710470199585 Best loss: 0.28793710470199585 Accuracy: 0.893333375453949 \n",
      "Epoch 406: Validation loss: 0.28790515661239624 Best loss: 0.28790515661239624 Accuracy: 0.893333375453949 \n",
      "Epoch 407: Validation loss: 0.2878742814064026 Best loss: 0.2878742814064026 Accuracy: 0.893333375453949 \n",
      "Epoch 408: Validation loss: 0.2878445088863373 Best loss: 0.2878445088863373 Accuracy: 0.893333375453949 \n",
      "Epoch 409: Validation loss: 0.28781574964523315 Best loss: 0.28781574964523315 Accuracy: 0.8933333158493042 \n",
      "Epoch 410: Validation loss: 0.2877880334854126 Best loss: 0.2877880334854126 Accuracy: 0.893333375453949 \n",
      "Epoch 411: Validation loss: 0.287761390209198 Best loss: 0.287761390209198 Accuracy: 0.893333375453949 \n",
      "Epoch 412: Validation loss: 0.2877357006072998 Best loss: 0.2877357006072998 Accuracy: 0.893333375453949 \n",
      "Epoch 413: Validation loss: 0.28771114349365234 Best loss: 0.28771114349365234 Accuracy: 0.893333375453949 \n",
      "Epoch 414: Validation loss: 0.2876875698566437 Best loss: 0.2876875698566437 Accuracy: 0.893333375453949 \n",
      "Epoch 415: Validation loss: 0.2876650393009186 Best loss: 0.2876650393009186 Accuracy: 0.893333375453949 \n",
      "Epoch 416: Validation loss: 0.28764352202415466 Best loss: 0.28764352202415466 Accuracy: 0.9000000357627869 \n",
      "Epoch 417: Validation loss: 0.28762301802635193 Best loss: 0.28762301802635193 Accuracy: 0.9000000357627869 \n",
      "Epoch 418: Validation loss: 0.287603497505188 Best loss: 0.287603497505188 Accuracy: 0.9000000357627869 \n",
      "Epoch 419: Validation loss: 0.28758504986763 Best loss: 0.28758504986763 Accuracy: 0.9000000357627869 \n",
      "Epoch 420: Validation loss: 0.28756752610206604 Best loss: 0.28756752610206604 Accuracy: 0.9000000357627869 \n",
      "Epoch 421: Validation loss: 0.28755098581314087 Best loss: 0.28755098581314087 Accuracy: 0.9000000357627869 \n",
      "Epoch 422: Validation loss: 0.28753548860549927 Best loss: 0.28753548860549927 Accuracy: 0.9000000357627869 \n",
      "Epoch 423: Validation loss: 0.2875208854675293 Best loss: 0.2875208854675293 Accuracy: 0.9000000357627869 \n",
      "Epoch 424: Validation loss: 0.2875072956085205 Best loss: 0.2875072956085205 Accuracy: 0.9000000357627869 \n",
      "Epoch 425: Validation loss: 0.2874947190284729 Best loss: 0.2874947190284729 Accuracy: 0.9000000357627869 \n",
      "Epoch 426: Validation loss: 0.2874830961227417 Best loss: 0.2874830961227417 Accuracy: 0.9000000357627869 \n",
      "Epoch 427: Validation loss: 0.2874724268913269 Best loss: 0.2874724268913269 Accuracy: 0.9000000357627869 \n",
      "Epoch 428: Validation loss: 0.28746265172958374 Best loss: 0.28746265172958374 Accuracy: 0.9000000357627869 \n",
      "Epoch 429: Validation loss: 0.28745391964912415 Best loss: 0.28745391964912415 Accuracy: 0.9000000357627869 \n",
      "Epoch 430: Validation loss: 0.2874460816383362 Best loss: 0.2874460816383362 Accuracy: 0.9000000357627869 \n",
      "Epoch 431: Validation loss: 0.287439227104187 Best loss: 0.287439227104187 Accuracy: 0.9000000357627869 \n",
      "Epoch 432: Validation loss: 0.2874332666397095 Best loss: 0.2874332666397095 Accuracy: 0.9000000357627869 \n",
      "Epoch 433: Validation loss: 0.2874281704425812 Best loss: 0.2874281704425812 Accuracy: 0.9000000357627869 \n",
      "Epoch 434: Validation loss: 0.28742408752441406 Best loss: 0.28742408752441406 Accuracy: 0.9000000357627869 \n",
      "Epoch 435: Validation loss: 0.2874208688735962 Best loss: 0.2874208688735962 Accuracy: 0.8999999761581421 \n",
      "Epoch 436: Validation loss: 0.2874186038970947 Best loss: 0.2874186038970947 Accuracy: 0.9000000357627869 \n",
      "Epoch 437: Validation loss: 0.28741729259490967 Best loss: 0.28741729259490967 Accuracy: 0.9000000357627869 \n",
      "Epoch 438: Validation loss: 0.28741681575775146 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 439: Validation loss: 0.2874172627925873 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 440: Validation loss: 0.2874186038970947 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 441: Validation loss: 0.2874208390712738 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 442: Validation loss: 0.2874239683151245 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 443: Validation loss: 0.28742796182632446 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 444: Validation loss: 0.28743278980255127 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 445: Validation loss: 0.2874385714530945 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 446: Validation loss: 0.28744518756866455 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 447: Validation loss: 0.2874526083469391 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 448: Validation loss: 0.28746098279953003 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 449: Validation loss: 0.28747013211250305 Best loss: 0.28741681575775146 Accuracy: 0.8999999761581421 \n",
      "Epoch 450: Validation loss: 0.2874801456928253 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 451: Validation loss: 0.2874910831451416 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 452: Validation loss: 0.28750279545783997 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 453: Validation loss: 0.2875152826309204 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 454: Validation loss: 0.2875286936759949 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 455: Validation loss: 0.2875429391860962 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 456: Validation loss: 0.2875578999519348 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Epoch 457: Validation loss: 0.28757375478744507 Best loss: 0.28741681575775146 Accuracy: 0.9000000357627869 \n",
      "Total training time: 979.2660403251648\n",
      "INFO:tensorflow:Restoring parameters from ./Team20_HW3_3_four_layers.ckpt\n",
      "Test accuracy:  0.851882\n"
     ]
    }
   ],
   "source": [
    "# some hyperparams\n",
    "batch_size = 128\n",
    "# An epoch means one iteration over all of the training data\n",
    "train_steps = round(len(X_train2) / batch_size)\n",
    "\n",
    "training_epochs = 1000\n",
    "# If validation loss does not improve after certain steps of training, apply early stopping\n",
    "early_stopping_epoch = 20\n",
    "\n",
    "# Early stopping variables\n",
    "best_loss = 10000000\n",
    "best_epoch = 0\n",
    "early_stopped = False\n",
    "\n",
    "# Prepare our training dataset with batch\n",
    "dataset_batch = tf.contrib.data.Dataset.from_tensor_slices((X_train2, y_train2)).batch(batch_size).repeat(training_epochs)\n",
    "dataset_batch = dataset_batch.make_initializable_iterator()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize\n",
    "    sess.run(init_g)\n",
    "    sess.run(dataset_batch.initializer)\n",
    "    \n",
    "    # restore our model\n",
    "    restore_saver.restore(sess, \"./hw2_model/Team20_HW2.ckpt\")\n",
    "    for var in output_layer:\n",
    "        var.initializer.run()\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training 1000 epochs\n",
    "    for epoch in range(0, training_epochs):\n",
    "        # Training steps\n",
    "        for i in range(train_steps):\n",
    "            X_in, y_in = sess.run(dataset_batch.get_next())\n",
    "            sess.run(training_op, feed_dict={x: X_in, y: y_in, training_mode: False})\n",
    "\n",
    "        # Validate accuracy every epoch\n",
    "        curr_loss, curr_accuracy = sess.run([loss, accuracy], feed_dict={x: X_valid2, y: y_valid2, training_mode: False})\n",
    "        \n",
    "        # Save checkpoint of current model if it performs better\n",
    "        if best_loss > curr_loss:\n",
    "            best_loss = curr_loss\n",
    "            save_path = saver.save(sess, \"./Team20_HW3_3_four_layers.ckpt\")\n",
    "            best_epoch = epoch        \n",
    "        # Early stop if model does not improve for certain epoch\n",
    "        elif epoch - best_epoch >= early_stopping_epoch:\n",
    "            early_stopped = True\n",
    "            break\n",
    "        \n",
    "        print(\"Epoch {}: Validation loss: {} Best loss: {} Accuracy: {} \".format(epoch, curr_loss, best_loss ,curr_accuracy))\n",
    "\n",
    "    # Save checkpoint in case the training is not early-stopped\n",
    "    if not early_stopped:\n",
    "        print(\"save best model\")\n",
    "        save_path = saver.save(sess, \"./Team20_HW3_3_four_layers.ckpt\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Total training time: \" + str(end_time - start_time))    \n",
    "    \n",
    "    # Get the best model\n",
    "    saver.restore(sess, \"./Team20_HW3_3_four_layers.ckpt\")\n",
    "    \n",
    "    # Total accuracy\n",
    "    final_accuracy = sess.run(accuracy, feed_dict={x: X_test2, y: y_test2, training_mode: False})\n",
    "    print(\"Test accuracy: \", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy of HW3.1 and HW3.2 are 0.821642\n",
    "#### Test accuracy of HW3.3 is 0.851882\n",
    "### Accuracy of HW3.3 is better than HW3.1&3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3.4  Bonus which extend HW3.3: only frozen third and fourth layers, and make first and second layers trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'dense0/kernel:0' shape=(784, 128) dtype=float32_ref>, <tf.Variable 'dense0/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'dense1/kernel:0' shape=(128, 128) dtype=float32_ref>, <tf.Variable 'dense1/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'logits_new/kernel:0' shape=(128, 5) dtype=float32_ref>, <tf.Variable 'logits_new/bias:0' shape=(5,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "# For AdamOptimizer\n",
    "learning_rate = 0.001\n",
    "n_classes = 5\n",
    "\n",
    "# import model from HW2\n",
    "restore_saver = tf.train.import_meta_graph(\"./hw2_model/Team20_HW2.ckpt.meta\")\n",
    "\n",
    "# Step1: Get tensor from HW2 model\n",
    "x = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"Y:0\")\n",
    "training_mode = tf.get_default_graph().get_tensor_by_name(\"is_training:0\")\n",
    "\n",
    "# Retrive the output of fourth layer\n",
    "fourth_dense_output = tf.get_default_graph().get_tensor_by_name(\"dense3/Elu:0\")\n",
    "\n",
    "# Make a new softmax layers\n",
    "logits = tf.layers.dense(inputs=fourth_dense_output, units=n_classes, kernel_initializer=\n",
    "                                    tf.contrib.layers.variance_scaling_initializer(), name='logits_new')\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits, name='sparse_cross_entropy')\n",
    "loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "\n",
    "# make layer trainable\n",
    "output_layer = []\n",
    "# Make first layer trainable\n",
    "output_layer.extend(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='dense0'))\n",
    "# Make second layer trainable\n",
    "output_layer.extend(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='dense1'))\n",
    "# Make softmax layer trainable\n",
    "output_layer.extend(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='logits_new'))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name='opt3_4')\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(logits, 1, output_type=tf.int32)\n",
    "correct_prediction = tf.equal(prediction, tf.cast(y, tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For initialize\n",
    "init_g = tf.global_variables_initializer()\n",
    "\n",
    "# Saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./hw2_model/Team20_HW2.ckpt\n",
      "Epoch 0: Validation loss: 1.3878096342086792 Best loss: 1.3878096342086792 Accuracy: 0.4399999976158142 \n",
      "Epoch 1: Validation loss: 0.8927179574966431 Best loss: 0.8927179574966431 Accuracy: 0.699999988079071 \n",
      "Epoch 2: Validation loss: 0.7505435943603516 Best loss: 0.7505435943603516 Accuracy: 0.7133333086967468 \n",
      "Epoch 3: Validation loss: 0.6249088048934937 Best loss: 0.6249088048934937 Accuracy: 0.800000011920929 \n",
      "Epoch 4: Validation loss: 0.528852641582489 Best loss: 0.528852641582489 Accuracy: 0.8466666340827942 \n",
      "Epoch 5: Validation loss: 0.477429062128067 Best loss: 0.477429062128067 Accuracy: 0.846666693687439 \n",
      "Epoch 6: Validation loss: 0.43718814849853516 Best loss: 0.43718814849853516 Accuracy: 0.8533333539962769 \n",
      "Epoch 7: Validation loss: 0.41405147314071655 Best loss: 0.41405147314071655 Accuracy: 0.8866666555404663 \n",
      "Epoch 8: Validation loss: 0.4017956554889679 Best loss: 0.4017956554889679 Accuracy: 0.8866666555404663 \n",
      "Epoch 9: Validation loss: 0.3919753134250641 Best loss: 0.3919753134250641 Accuracy: 0.8799999952316284 \n",
      "Epoch 10: Validation loss: 0.3838760554790497 Best loss: 0.3838760554790497 Accuracy: 0.8799999952316284 \n",
      "Epoch 11: Validation loss: 0.374911367893219 Best loss: 0.374911367893219 Accuracy: 0.8733333349227905 \n",
      "Epoch 12: Validation loss: 0.36581629514694214 Best loss: 0.36581629514694214 Accuracy: 0.8799999952316284 \n",
      "Epoch 13: Validation loss: 0.3602246046066284 Best loss: 0.3602246046066284 Accuracy: 0.8799999952316284 \n",
      "Epoch 14: Validation loss: 0.35763856768608093 Best loss: 0.35763856768608093 Accuracy: 0.8733332753181458 \n",
      "Epoch 15: Validation loss: 0.35545992851257324 Best loss: 0.35545992851257324 Accuracy: 0.8866666555404663 \n",
      "Epoch 16: Validation loss: 0.3527511954307556 Best loss: 0.3527511954307556 Accuracy: 0.8866666555404663 \n",
      "Epoch 17: Validation loss: 0.3498148024082184 Best loss: 0.3498148024082184 Accuracy: 0.8866666555404663 \n",
      "Epoch 18: Validation loss: 0.34742239117622375 Best loss: 0.34742239117622375 Accuracy: 0.8933333158493042 \n",
      "Epoch 19: Validation loss: 0.34591126441955566 Best loss: 0.34591126441955566 Accuracy: 0.8933333158493042 \n",
      "Epoch 20: Validation loss: 0.344775915145874 Best loss: 0.344775915145874 Accuracy: 0.8999999761581421 \n",
      "Epoch 21: Validation loss: 0.34355831146240234 Best loss: 0.34355831146240234 Accuracy: 0.8999999761581421 \n",
      "Epoch 22: Validation loss: 0.3423607647418976 Best loss: 0.3423607647418976 Accuracy: 0.8999999761581421 \n",
      "Epoch 23: Validation loss: 0.34145379066467285 Best loss: 0.34145379066467285 Accuracy: 0.9000000357627869 \n",
      "Epoch 24: Validation loss: 0.3409194052219391 Best loss: 0.3409194052219391 Accuracy: 0.9133332967758179 \n",
      "Epoch 25: Validation loss: 0.34064072370529175 Best loss: 0.34064072370529175 Accuracy: 0.9199999570846558 \n",
      "Epoch 26: Validation loss: 0.34046539664268494 Best loss: 0.34046539664268494 Accuracy: 0.9199999570846558 \n",
      "Epoch 27: Validation loss: 0.3403819501399994 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 28: Validation loss: 0.3404705822467804 Best loss: 0.3403819501399994 Accuracy: 0.9200000166893005 \n",
      "Epoch 29: Validation loss: 0.34074872732162476 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 30: Validation loss: 0.34113970398902893 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 31: Validation loss: 0.3415466248989105 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 32: Validation loss: 0.3419359624385834 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 33: Validation loss: 0.3423444926738739 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 34: Validation loss: 0.3428196609020233 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 35: Validation loss: 0.3433718979358673 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 36: Validation loss: 0.3439651429653168 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 37: Validation loss: 0.3445521593093872 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 38: Validation loss: 0.34511375427246094 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 39: Validation loss: 0.3456634283065796 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 40: Validation loss: 0.34622499346733093 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 41: Validation loss: 0.3468104600906372 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 42: Validation loss: 0.3474150598049164 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 43: Validation loss: 0.3480251133441925 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 44: Validation loss: 0.34862828254699707 Best loss: 0.3403819501399994 Accuracy: 0.9199999570846558 \n",
      "Epoch 45: Validation loss: 0.3492204546928406 Best loss: 0.3403819501399994 Accuracy: 0.9266666173934937 \n",
      "Epoch 46: Validation loss: 0.3498063385486603 Best loss: 0.3403819501399994 Accuracy: 0.9266666173934937 \n",
      "Total training time: 99.22416234016418\n",
      "INFO:tensorflow:Restoring parameters from ./Team20_HW3_4_bonus.ckpt\n",
      "Test accuracy:  0.902901\n"
     ]
    }
   ],
   "source": [
    "# some hyperparams\n",
    "batch_size = 128\n",
    "# An epoch means one iteration over all of the training data\n",
    "train_steps = round(len(X_train2) / batch_size)\n",
    "\n",
    "training_epochs = 1000\n",
    "# If validation loss does not improve after certain steps of training, apply early stopping\n",
    "early_stopping_epoch = 20\n",
    "\n",
    "# Early stopping variables\n",
    "best_loss = 10000000\n",
    "best_epoch = 0\n",
    "early_stopped = False\n",
    "\n",
    "# Prepare our training dataset with batch\n",
    "dataset_batch = tf.contrib.data.Dataset.from_tensor_slices((X_train2, y_train2)).batch(batch_size).repeat(training_epochs)\n",
    "dataset_batch = dataset_batch.make_initializable_iterator()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize\n",
    "    sess.run(init_g)\n",
    "    sess.run(dataset_batch.initializer)\n",
    "    \n",
    "    # restore our model\n",
    "    restore_saver.restore(sess, \"./hw2_model/Team20_HW2.ckpt\")\n",
    "    for var in output_layer:\n",
    "        var.initializer.run()\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training 1000 epochs\n",
    "    for epoch in range(0, training_epochs):\n",
    "        # Training steps\n",
    "        for i in range(train_steps):\n",
    "            X_in, y_in = sess.run(dataset_batch.get_next())\n",
    "            sess.run(training_op, feed_dict={x: X_in, y: y_in, training_mode: False})\n",
    "\n",
    "        # Validate accuracy every epoch\n",
    "        curr_loss, curr_accuracy = sess.run([loss, accuracy], feed_dict={x: X_valid2, y: y_valid2, training_mode: False})\n",
    "        \n",
    "        # Save checkpoint of current model if it performs better\n",
    "        if best_loss > curr_loss:\n",
    "            best_loss = curr_loss\n",
    "            save_path = saver.save(sess, \"./Team20_HW3_4_bonus.ckpt\")\n",
    "            best_epoch = epoch        \n",
    "        # Early stop if model does not improve for certain epoch\n",
    "        elif epoch - best_epoch >= early_stopping_epoch:\n",
    "            early_stopped = True\n",
    "            break\n",
    "        \n",
    "        print(\"Epoch {}: Validation loss: {} Best loss: {} Accuracy: {} \".format(epoch, curr_loss, best_loss ,curr_accuracy))\n",
    "\n",
    "    # Save checkpoint in case the training is not early-stopped\n",
    "    if not early_stopped:\n",
    "        print(\"save best model\")\n",
    "        save_path = saver.save(sess, \"./Team20_HW3_4_bonus.ckpt\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Total training time: \" + str(end_time - start_time))    \n",
    "    \n",
    "    # Get the best model\n",
    "    saver.restore(sess, \"./Team20_HW3_4_bonus.ckpt\")\n",
    "    \n",
    "    # Total accuracy\n",
    "    final_accuracy = sess.run(accuracy, feed_dict={x: X_test2, y: y_test2, training_mode: False})\n",
    "    print(\"Test accuracy: \", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Test accuracy of HW3.3 is 0.851882\n",
    "#### Test accuracy of HW3.4 is 0.902901\n",
    "### Accuracy of HW3.4 is better than HW3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
